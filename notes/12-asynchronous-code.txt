Asynchronous code
Introduction:
Since javascriptg is the language of the web, thre are some functions that by necessity are goingt o take a decent
amount of itme to cpmlete, sucha s fetching data from a server to display on your site. For this reason, jagvascdript includes
support for asynchrounous functions, or to put it another way, functions that can happen in the background while the rest of your code executes.

Lesson OVerveiw:
This section contains a general overview of topics you will learn in this lesson. Explain what a callback is
explain what a promise is
explain the circumsttance which promises are better than clalbacks
explain the .then() functions

Callbacks:
In the recent past, the way that these were most commonly handled were with callbacks, and even now they are stil use
quite a lot in certain circumstances.
A callback fucniton is a function passed into another function as an argument, which is then invoked inside the outer function to complete some kind of routine or aciton.

Callbacks are functions that get passed into other functions.

For example:
    myDiv.addEventListern("click", function()){
    DO SOMETHINGGG
    }

Here, the function addEventListern() takes a callback ("the do something" funciton) and then aclls it when myDiv gest clicked>
YOu will likely recognize htis pattern as something that hpapens all the time in javascript code.
Unfortuantely, though they are useful in situations like the above example,Â using callbacks can get out of hand, especially when you need to chain several of htem together in a specific
order. the rest of htis lesson discusses pattersn and functions that will help keep you out of callback hell.

Promises:
There are multiple ways that you can handle asynchronous code in JavaScrfipt, and they all have their use cases.
Promises are one such mechanism, and they're on you will see somewhat often when using other libraries or frameworks. Knowing 
what thye are and how to use them is quite useful.

Essentially, a promise is an object that might produce a value at some point in the future.

Lets say getData()is a function that fetches some data from a server and retunrs it as on object that we can use in our code:

const getData = function() {
    //go fetch data from some APi
    //clean it up a bit return it as an object
    return data.
}
The issue with this example is that it takes some time to fetche the data, but unless we tell our code that, it assumes that everything in the funciton happens essentially instantly.

So if we try this:
const myData = getData()
const pieceOfData = myData["whatever"]

WE're going to run into trouble because when we try to extract pieceOfData out of the returned data,
the funciton getData() will mostlikely still be fetchingh, so myData will not be the expected data,
but will be undefined. Sad.

We need some way to solve this problem, and tell our code to wait until the data is done fetching to continue. Promises solve this issue. 



const myData = getData() //if this is refactored to return a promise...


myData.then(function(data) [//.,then() tell is to wait until the promise is resolved
    const pieceOfData = data["whatever]//and THEN run the function inside.
])



Article:https://davidwalsh.name/promises

While synchronous code is easeir to follow and debug, async is generally ebtter for performance and flexiibility.
Why "hold up the show" when you can trigger numerous requests at once and then handle them when each si ready?
Promsies are becoming a big part of the javascript world, with many new APIS being implemented witht hep rmose philosophy.


Promises in the wild:
The XMLHttpRequest API is async but does NOT use the promises API. TGhere are a few native apis that now use promises however.
    Battery API
    fetch API
    ServiceWorker API

Promises will only become more prevalent so its important that allf ront-end developers get used to them.
Its also worht noting that node.js is another platform for promises. Obviously as promise is a core language features.

Basic Promise Usage:
The new Promise() constructor should only be used fo rlegacy async tasks, like the usage of setTimeout or XMLHttpRequest. 
AA new promsie is created with the new keyword and the promise provides resolvea dn reject funcitons to the provided callback:

var p = new Promise(function(resolve, reject) {
	
	// Do an async task async task and then...

	if(/* good condition */) {
		resolve('Success!');
	}
	else {
		reject('Failure!');
	}
});

p.then(function(result) { 
	/* do something with the result */
}).catch(function() {
	/* error : */
}).finally(function() {
   /* executes regardless or success for failure */ 
});



Sometimes you dont NEED to complete an async takss within the promise.
returning a promise will be best so taht you can always count on ap romise coming out of a given fucniton.
IN that case, you acn simply call promise.reolve() of promise.reject() without using the new keyword


Callbacks: https://github.com/getify/You-Dont-Know-JS/blob/1st-ed/async%20%26%20performance/ch2.md

IN chapter 1, we explored the terminology adn concepts around asynchronous programming in javascript.
Our focus is onudnerstandint he single-threaded (one at a time) event lop queue that
drives all events. WE also explored vairous ways that concurrency pattersn explains the relationshipos
between any simultaneously running chains of events, or processes.

All oru examples in chapter 1 use the funciton as the individual, indivisible unit of operations, whereby inside
the funciton, statements run in predictrable order ( above the ocmpiler level) but at the
funciton ordering level, events (aka async funciton invocations) can happen in a variety or ordres.

In all these cases, the funciton is a cting as a "callback" because it serves as the target for the event loop
to "call back into" the program, whenever that item in theq eueu is processed.

As you no doubt have observed, callbacks are by far the most common way that asynchronoy in JavaScrfipt
prorams is expressed and managed. Inded, the callback is the most fundamental async pattenr in the language.


Countless JS programs, even very sophisticated and compelx ones, have been written upon no other async foundation than the callback.
(with of course the concurrency interaction patterns we explored in chapte r1) The callback fucniton is the async work horse for javascript, and it does its job respectabl.

Except... Callbacks are not without their shortcomings. Many developers are excited by the PROMSE of better async patterns. But its impossible to effectively use any abstraciton if you don't
understand what its abstracting, and whyl.


Continuations:

// A
ajax( "..", function(..){
	// C
} );
// B


// A and // B represent the first half of the program (aka the now), and // C marks the second half of the program (aka the later). The first half executes right away, and then there's a "pause" of indeterminate length. At some future moment, if the Ajax call completes, then the program will pick up where it left off, and continue with the second half.

In other words, the callback function wraps or encapsulates the continuation of the program.

Let's make the code even simpler:

// A
setTimeout( function(){
	// C
}, 1000 );
// B


Stop for a moment and ask yourself how you'd descrfibe the wayt hat program behaves. 
try it out loud. Its a good exercise that will help my next points make sense.


Most readres just now probably thought or said something to the effect of: "Do A, then set up a setTimeout
to wait1,000 milliseconds, then once that fires, do c. How close was your rendition?

You might have cauvht yourself and self-edited to: "do A, setup the timeout for 1,000 milliseconds, then
do b, then after the timeout fires, do C. Thats more accurate thatn the first version


Even though the second version is more accurate, both versions are deficient in explaining this code
in a way that matches our brains to the code and the code to the JS engine. The disconnect is both subtle and monumental.
and is at the very herat of understanding the shortcomings of callbacks as async expression and management.

As soon as we introduce a single fcontiuation. In the ofrm of a callback function, we have a allowed a divergence
to form between how our brains work and the way th ecode will operate. Any time these two diverge (and this is by far no the only place that happens,)
we run into the inevitable fact that our code becomes harder to udnerstand, reason about, debug, and maintain.


Sequential Brain:
I'm pretty sure most of your readeres have heard someone say "i'm a multitasker" The effects of trying to act
as  a multitasker range from humorous to mundane to downright dangerous.

But are we multitaskers? Can we really do two conscious, intentional actions at once and think/reason about both of htem at 
exactly the samem moment? Does our highest level of brain funcitonality have parallel multithreading going on?
probably not.



Thats just not really how our brains appear to be set up. We're much more single taskers than many of us would like to admit.
We can really only think about one thing at anygiven instant.

I'm not talking about all our invaluntary, subconciuos, automatic brain functions, suchas heart beating, breathing, and eyelid blinking.
Thes are all vital tasks to our sustained life, but we don't intentionally allcoate any rbain power to them.
Thankfully, while we obsses about checking social network feeds for the 15th time in three minutes, our brain carries on in the background (Threads!) 
withall those important tasks.

WE're instead talking about whatever task is at the forefront of our minds at the moment. For me its writing the text in this book right now.
Am I doing any other higher level brain function at exactly this same moement? Nope, not really. I get disttracted quickly and easily -- a few
dozen times in thes last couple of paragraphs!

WHen we fake multitasking, such as trying to type something at the same ttime we're talking to a friend or family emmeber on the phone,
what we're actually most likely doing is acting as fast context switchers. In other words, we switch back and forth bewtween two or more tasks in rapid succession, 
simultaneously progressing on each task in tiny, fast little cunks. We do it so fast that to the outside world it appears as if we're doing those things in parallel.

DSoes that sound suspiciously like async evented concurrency to you?
If not, go back and read chapter 1 again!

In fact, one way of simplifying, the massively complex world of neurology into somethign I can remotely hope to discuss here is that our brains work kind like the event loop queue.

If you think about every single letter or word I type as a single async event, in jsut this sentence alone there are severeal dozen opportunities for my brain to be interrupted by some tother event, 
such as from m y sense, or even just my random thoughts.

I don't get interrupted and pulled ot another "process" at every oppporutnity that I could be.
But it happens often enough that I feel my own brain is nearly constanlty switching to variou sdifferent contexts and thats an awful lot like howt he js engine would probably fel.


DOING VS PLANNING:
Ok so our brains can thought of as operating in single threaded event loop queue like ways, as can the JS engine.
But we need to be more nuanced than that in our analysis. There's a big, observable difference between how we plan various tasks,
and how our brains actually operate those tasks.

Again, back ot the wriitng of htis text as my metahpor,. My rough mental outline plan here is to keep wriitng and writing,
going sequentially through a set of points I have ordered in my thoguhts. I don't plan to have any interruptions or nonlinear activity in this wriitng.
But yeet, my brain is nevertheless swithcing around all the time.

Even though at an operational level our brains are async event3ed, weseem to plaln out tasks in a sequqneial synchronous wayl. "i nee to go to the store then buy some ilk, then drop off my dry cleaning".

You'll noce that this higher level thinking doesn't seem very async event3ed in its formulation.
In fact, its kidn of rare for us to delibterately think solely in terms of events. Intead, we lan things out carefully, sequentially,
and then we assume to an extrent a sort of temporal blocking that forces b to wai t on A and c to wa it on B.

When a developer writews code, they are planning out a set of actions to occur. If htey're any good at being a developer, they're carefully planning it out. I need to set z to the value ofx, then x to the value of y and so forth..
z = x;
x = 7;
y = x;

These three assignment statements are synchronous, so x=y waits for x=x to finish, and y = z in tyrn ways for x=7 to finish. 
Another way of saying it is that these three statements are temporarily bound to execute in a certain order, one right after the other. Thankfully, we don't need to be bothered with any async evented details here.

So if synchronous brain planning maps well to synchronous code statement,s how well do our brains at planning out asynchronous code?
It turnms out how we express asynchronoy in our code doesn't map very well at all to that synchronous brain planning behavior.

We think in step by step terms, but the tools (callbacks) available to us in code aren ot expressed in a step by step fashion once we move from synchronous to asynchronous.

And THAT is why its so hard to accurately author and reason about async JS code with callbacks:
because thats now how our pbrain planing works.
Note: The only thing worse than not knowing why some code breaks is not knowing why it worked in the first place! It's the classic "house of cards" mentality: "it works, but not sure why, so nobody touch it!" You may have heard, "Hell is other people" (Sartre), and the programmer meme twist, "Hell is other people's code." I believe truly: "Hell is not understanding my own code." And callbacks are one main culprit.



Nested/Chained callbacks:
listen( "click", function handler(evt){
	setTimeout( function request(){
		ajax( "http://some.url.1", function response(text){
			if (text == "hello") {
				handler();
			}
			else if (text == "world") {
				request();
			}
		} );
	}, 500) ;
} );

Threres a good chance code like that is recognizable to you. WE've got a chian of three funcitons ensted together, each one representing a step in an asynchronous series.


This kidn of code is often called "callback hell" and sometimes also referred to as the pyramid of dooml.

But callback hell actually has almost nothing to do with the nesting/inentatin. Its a far deeper problem than that. We'll see how and why as we continue through the rest of this chapter.

FIrst we're waiting for the "click" event, then we're waiting for hte timer to fire, then we're waiting for hte ajax repsponse to come back ,and which point we might do it alla gian.


listen( "click", handler );

function handler() {
	setTimeout( request, 500 );
}

function request(){
	ajax( "http://some.url.1", response );
}

function response(text){
	if (text == "hello") {
		handler();
	}
	else if (text == "world") {
		request();
	}
}

This formulation of the code is not hardly as recognizxable as hagving the nesting/indentation woes of its previous form,
and yet its every bit as suceptible to"callback hell". WHy?

As we go linearly (sequentially reason) about this code, we have to skip from one function to hte next,
to the next, and bounce all around the code base to see the qsequence flow.
As remember, this is simplified code in sort of best-case fashion, We all know that real async JS p[rogram code bases are
often fantastically more jmbled, which makes such reasoning order of magnitude more difficult]


Another thing to noice: to get steps 2,3, and 4 linked together so they happen in succession, the noly affordance callbacks alone
gives us to hardcore step 2 into step 1, step 3 into step 22, step 4 into step 3 asnd so on. The hardcoding isn't necessarily a bad thing, if it
really is a fixed condition that step 2 should always lead to step 3.

But the hardcoding defnitely makes the code a bit more brittle, as it doesn't account for angything going wrong
that might cause a edeviation int he progression of steps. For exapmle, if step 2 fails, step 3 never gets reached, nord oes step 2 retry, or move ot an alternate error handling flow, and so on.


All of these issues are things you CAN manually hardcode into each step, but that code is often very repetetive and not reuseable in other steps or in other async flows in your program.

Even though our brains might plan out a series of tasks in a sequential type of way (this, then this, then this) the evented nature of our brain operation makes recovery retry forking of flow control almsot efortless.
If you're out r unning errands, and you realize you left a shoppin glist at home, it doesn't end the day b ecause you didn't plan that ahead of itme. your brain routes aroudn this hiccup easily: you got home, get a list, then head right back out to the store.


But the brittle nature of manually hardocded callbacks (even with haredcoded error handling) is often far less graceful. Once you end up speciiying (aka preplaning) all the various eventulaities/paths,
the code becomes so convoluted that it s hard to ever maintain or update it.

THAT is what "callback hell" is all about! The nesting/indentation are basically a side show, a red herring.

And as if all thats not enough, we haven't even touched what happens hen two or more chains of thse callback contiuatinos are happening SIMULATANEOUSLY, or whent eh third step branches out in "parallel" callbacks
with gates or latches/



Trust ISSUES:
The mismatch between sequential brain planning and callback driven async js code is the only part o the problem wit h callbacks. Theres somethign muchd eeper to be concerned about.

// A
ajax( "..", function(..){
	// C
} );
// B

// A and // B happeng NOW, under the direct control of the main JS program. but //c gets deferred to happen later, and udner the contorl of anothe rparty -- in this case, the ajax(..) funciton. In a basic sense,
that sort of hand-off of o control doesn't regularly cause lots of problems for programs.


But don't be fooled by its infrequency that this control switch isn't a bitg deal. in fact, its one of the worst (and yet most subtle) problems
about callbacjk-driven design. It reolves around the idea that sometimes 
the party that hnaldes your callback contuation is not a function that you wrote, or that you direclty control.
Many times, its a utility provided by some third party.

WE call this "inversion of control", when you take part o fyour program and give control of its executiont o another third party. There's an unspoken
"contract" that e4xists between your code and the third party utility -- a set of htings youe xpect to be maintained.


Tale of five callbacks:
It might noe bt terribly obvious why this is such a big deal. Let me construct an exaggerated scenario to illustrate the hazards of trust at play.

IMagine yoiu're a developer taske with building out an ecommerce checkout system for a site that sells expesnive TV's. You alreaedy have all the various pages of the checkout stystem builto ut just fine.
 On the last page, when the user clicks "confirm" to buy the TV, you need to call a third-party function so that the sale can be tracked.

 You noticve that htye've provided what looks like an asynct racking utility, probably for the sak eof performance best practices, which means you need to pass in a callback funciton. in this contiunation that you pass in,
 you will have the final code that charges the customer's cr3edit card and dislays the thank yo upage.

 analytics.trackPurchase( purchaseData, function(){
	chargeCreditCard();
	displayThankyouPage();
} );

Easy enough, right? You write the code, test it, eerything works, and you deploy to production> everyone's happy.

Six months go by anad no isues. You've almost forgotten you even wrote that code. Once morning you're at a coffee shop before work, casually enjoyuing your latte, when you get pacnkicked clal form your boss
insisting you drop the coffe and rush into work right away.

When you arrive, you'll findo ut that high profile customer has his credit card charrged five times for the same tv, and he's understandbly upset. CUstomer service has already issued
an apology and processed a refund. But your boiss demsnds to know how this could possibly have happened. "don't we have tests for stuff like this?"

YOu don't even rememebr the code you wrote. But you dig back in and start trying to find out what could ahve gone awry.

AFter digging through some logs, you come to the conclusion that the only explanation is that the analytics utilty somehow, for some reason, called your callback five times tinstead of once. Nohting in their documentation mentions anything baout this.

Frustratec,you ocontat customer support, who of course is as astonished as you are. They agree to escalate it to their developers and promose to get back to you.
The next day, you recive aq lenghty email explaining what they found, which you promptly forward to your boss.

Apparently, the developers at the analytics companyh had been working on some experimetnba code that, uner ertain conditions, would retry to the provided callback once per second, for five seconds, before fialing with a timeout.
They had never inteded to push that into production, but somehow they did, and they're totally embarassed and apologetic. They go into plenty of detail about how they've
identified the breakdown adn what they'll do to ensure it enver happens again.yadda, yadda.
Whats next?

YOu talk it over with your boss, but hes not feeling particularly comfortable witht eh state of things. he insi9sts, and you reluctantly agree, taht you fan't trust tthem anymore
and that you'll need to figure out how to protect hte checkout code from such a vulnerability again.


Example code for tracking checkouts.
var tracked = false;

analytics.trackPurchase( purchaseData, function(){
	if (!tracked) {
		tracked = true;
		chargeCreditCard();
		displayThankyouPage();
	}
} );

But one of your WA engineers asks "What happen sif they never call the callback? Oops. Neitehr of you had thought about that.

You beging to chase down the rabbit hole, and think of all the possible things that could go wrong weith them calling your callback.
Here's roughly the list you come up with of ways the analytics utility could misbehave:

	Call the callback too early (before its been tracked)
	Call the callback too late (or never)
	call the callback too few or too many times (like the problem you encountered!)
	Fail to pass along any necessary environment/parameters to your callback.
	Swallow any errors/exceptions that may happen.

That hsould feel like a troubling list, because it is. You're probably slowly starting to realize that you're going to have to invent an awful lot of ad hoc logic in each and every single callback
thats passed to a utility you're not positive you can trust.
Now yo realize a bit more completely just how hellish "callback hell is"


Not just others code:
Some of you mayu be skeptical at this point whether this is as big a deal as i'm making it out to be. Perhaps you don't interact wiht truly third-party utilities much if at all.
Herpahs you use version APIS or self-host such lirbaries, sot aht tis behavior can't be changed out from underneath you.

So contemplate this: can you even REALLY trust utilities that you do theoretically control in your own code base?

Think of it this way: most of us agree that at least to some extent we should bulid our own internal functions ith some defensive checks ont he input parameters,  to reduce/prevent uenxepcted issues.

function addNumbers(x,y) {
	// + is overloaded with coercion to also be
	// string concatenation, so this operation
	// isn't strictly safe depending on what's
	// passed in.
	return x + y;
}

addNumbers( 21, 21 );	// 42
addNumbers( 21, "21" );	// "2121"

Defensive version of code:
function addNumbers(x,y) {
	// ensure numerical input
	if (typeof x != "number" || typeof y != "number") {
		throw Error( "Bad parameters" );
	}

	// if we get here, + will safely do numeric addition
	return x + y;
}

addNumbers( 21, 21 );	// 42
addNumbers( 21, "21" );	// Error: "Bad parameters"




However you go about it, these sorts of checks/normalizations are failry common on fucntion inputs, evne with code we theoretically entirely trust. IN a crude sort of way, its like the programming equivalent of the geopolitical principle fo "trust but verify"

So doesn't it stadn to treason that we should do the same thing about the copmosition of async funciton callbacks, not just with truly external code but even with code we know is generall udner our own control? OF COURSE WE SHOULD.

But callbacks don't really offer anythign to assist us. We have to construct all that machinery ourselves, and it often ends up being a lot of boilerplate/overhead that we repeat for every single async callback.
The most troublesome problem with callbacks is inversion of control leading to a complete breakdown along those trust lines. If you ahve code tha tuses callbacks,
especially but not exclusively with third-party utilties, and you're not already aplying some sort of mitigation logic for all thes e inversion of contrrol trust issues, your code AHS bugs in it right now even thought ehy nay not have beitten you yet.
Latent bugs ar estill bugs,. Hell indeed.


Trying to save calllbacks:
There are several variations of callback design that have attempted toa ddress some (not all!) of the trust issues we've just looked at.
Its a valiant, but doomed, effort to save the callback pattern from imploding on itself.

function success(data) {
	console.log( data );
}

function failure(err) {
	console.error( err );
}

ajax( "http://some.url.1", success, failure );

In APIS of this desing, oftne the failure()error handler is optional, and if not provided it will be assumed you want thte erros swallowed. Ugh.

NOte: THis split-callback design is what hte ES6 promise API uses. WE'll coer ES6 promises in much more detail in the enext chapter.

Another common callback pattern is called "error-first style" sometimes called node style as its also the convention used accross nearly all node.js APIs where the first argument
of a single callback is reserved for an error object. If any. If succes, this argumetn will be empty/falsy and any subsequent arguments will be the success data but ifan error
result is being signaled, the first argument is set/truthy and nusually nothign else is passed.

function response(err,data) {
	// error?
	if (err) {
		console.error( err );
	}
	// otherwise, assume success
	else {
		console.log( data );
	}
}

ajax( "http://some.url.1", response );


IN both of htese cases, several things hsould be observed.
First, it has not really resolved the majority of trust issues like it may appear. There's ntohign about eitehr callbac that prevents or filters unwanted repeatd invocations. Morever, things are worse now,
because you may get both success and eror signals, or noeither, and you still have to code around either of those conditions.

Also don't miss the fact that while its a standard pattern you can employ, its definitely more verbose and boilerplate-ish without much reuse, so you're going to get weary of typing all that out for everyf single callback in your application.
What about hte trust issue of never being calle? If  this is a concern (and it probably should be!) yo ulike will need to set up a timeout that cancels the event. you could make
a utility 

function timeoutify(fn,delay) {
	var intv = setTimeout( function(){
			intv = null;
			fn( new Error( "Timeout!" ) );
		}, delay )
	;

	return function() {
		// timeout hasn't happened yet?
		if (intv) {
			clearTimeout( intv );
			fn.apply( this, [ null ].concat( [].slice.call( arguments ) ) );
		}
	};
}

Anotehr trust issue is being called "too early" In application specific terms, this may actually involve being called
before some critical task is complete. But more generally, the problem is evident in utilities that can either invoke the callback you provide now (synchronously) or later (asynchronously)

This nondeterminism around the async-or-async behavior is almost always going to lead to very difficult to track down bugs. In some circles, the fictional insanity-inducin monster
named Zalgo is used to describe the sync-async nightmores. "don't release Zalgo!" is a common cry, and it leads to very sound advice.
Always invoke callbacks asynchronously, even if that's "right away" on the next turn of the ven tloop, so that all callbacks are predictably async.

The asynchronous request in the cache "solves" the issue, but its inefficient, and yet again more bloated boilerplate to weight your project down.
Thats just hte sotry, ove rande over again, with callbacks. They can do prety much anything youw ant. But you ahve to be willign to work hard to ge tit,
and oftentimes this effort is much more than you can or should spend on such code reasoning.

You might find yourself wishig for built-in API's or other language mechanics toa ddress these isuses.
Finnaly ES6 ha arrived ont he scen with some great answers, so keep reading!

Review:
Callbacks are the fundamental unit of asynchrony in JS. but they're not enough for the evolving landscape of async programming as JS matures.

FIrst, our brains plan things out in sequential, blocking, single-threaded semantic ways bt callbacks express asynchronous flow in a rather nonlinear, nonsequential way, whihc makes reassoning properly 
about such code much harder. Bad to reason about code is bad tcod etha tleads to bad bugs. 

We need a way to express asynchrony in a more synchronus, sequntial, blocking manner, just like our brains do.
We need a way to express asynchrony in a more synchronous, sequential, blocking manner, just like our brains do.

Second, and more importantly, callbacks suffer from inversion of control in that they implicitly give control over to another party (often a third-party utility not in your control!) to invoke the continuation of your program. This control transfer leads us to a troubling list of trust issues, such as whether the callback is called more times than we expect.

Inventing ad hoc logic to solve these trust issues is possible, but it's more difficult than it should be, and it produces clunkier and harder to maintain code, as well as code that is likely insufficiently protected from these hazards until you get visibly bitten by the bugs.

We need a generalized solution to all of the trust issues, one that can be reused for as many callbacks as we create without all the extra boilerplate overhead.

We need something better than callbacks. They've served us well to this point, but the future of JavaScript demands more sophisticated and capable async patterns. The subsequent chapters in this book will dive into those emerging evolutions.




u-Dont-Know-JS/blob/1st-ed/async%20%26%20performance/ch3.md
You don't know JS: ASYNC AND PERFORMANCE
Chapter 3: Promises.

In chapter 2, we identified two major categories of deficiencies with using callbacks to express program asynchrony and manage concurrency.
Lack of sequentiality and lack of trustability. Now that we understand the problems more intimately, its time we turn our attention to patterns that can address them.

The issue we want to address first is the inversion of controlk, the trust that is so frageily held and so easily lost.

Recall that we wrap up the contiuation of our program in a  callback function, and hand that callback over to another party
(potentially even external code) and just cross our fingers that it willl do the right thing with the invocatin of the callback.
We do this because we want to say that "here what happens LATER, after the currne step finishes"
But hwat if we could uninvert the inversion of cohntrol? What if instead of handing the continuation of our program to another party, we could expect it to return us a capability
to know when its task finishes, and then our code could decide what to do next?


This paradigm is called PROMISES.
Promises are starting to take the javascript world by storm ,as deveopers and specification writers alike desperately seek to untangle the insanity of callback hell in their code/desin. In fact,
most new async APIs are being added to JS/DOM platform are being built on promises. So its probably a good idea to dig in and learn hteml, don't you thinK?


What is a promise?:
When developers decide to learn a new tehcnology or pattern, usually their first step is "show me the code!" its quite natural for us ot just jump in and learn as we go.
But it turn sout that some abstractions get lost on the APIS alone. Promises are one of htose tools where it can be painfully obvious from how someone uses it whether they udnerstand what its for and about
vereuss just learning  and using the API.

Future Value:
IMagine this scenario: I walk up to the counter at a fast-food restaurant and place an  orer for a cheeseburger. I hand the cvashier 1.47. By placing my order and paying for it, I've made a request for a value back (the cheeseburger)
I've started a transaction.
But often, the cheesebruger is not immediately available for me. The cashier hands me something in place of my cheeseburger: a receipt with an order number on it. THi soder numebr is an IOU PROMISE that ensures
that eventually, I shoudl receive a cheesebruger.

So I hold onto my receipt and order number. I know it rerpesents my future cheeseburger, so I don't need to wayy about ti anymore -- aside from being hungry!

While I wait, I can do other things, like send a text message to af riend saying "hey can you come join me for lunch? I'm going to eat a cheeseburger."

I am reasoning about my FUTURE fcheeseburger already, even though I don't have it ihn my haneds yet. My brain
is able to do this beecause its treating the order number as a placeholder for the cheeseurger. The placeholder essentially amkes the value time independent. Its a future value.


Eventulaly I hear "Order 113!" and I gleefully walk back up to th ecounter wiht receipt in hand. I hand my receip tto ehc cashier, and I take my cheeseburger in return.
In other words, once my future value was ready, I exchanged my value-promise for the value itself.

But there's another possible outcome. They call my order number, but when I go to retrieve my cheeseburger, the cashier
regretfully informs me, I'm sorry, but we we appear to be all out of cheeseburgerS" Setting aside the customer frustration of htis scenario for a moement, we can see
an important characteristic of future values: They ca n either indicate a success or failure.

Every time I order a cheeseburer, I know that i'll eitehr get a cheeseburger eventually, or i'll get the sad news of th cheesebrger shortage, and I"ll have to figure out something else to eat for lunch.
Note: In ocde, things are not quite as simple, because metaphorically the order number may never be called, in which case we're left indefinitely in an unresolved state.


Values now and later:
This all might soudn too mentally abstract to apply to your code, so lets be more concrete. 
However, before we canintroduce how promises work in this fashion, we're going to derivce in code that we already udnerstand. Callbacks! How to handle these future values.
When you write code too reason about a value, such as perfomring math on a number, whether you realize it or not, you've been assuming something very fundamentalabout that value, which is that its s a contcrete now value.


var x, y = 2;

console.log( x + y ); // NaN  <-- because `x` isn't set yet

The x + y operation assumes both x and y are alrady set. In terms we'll expounnd on shortly, we assume the x and y values are already resolved.

It would be nonsense to expeft the + operator by itself would somehow be magicvally capable
of detecting and waiting around until both x and y are resolved, only then to do the operation.
That owuld cause chaos in the program if different statements finished NOW and others finishhed later right?


How oculd you possibly reason about the relationships between two statements if either one (or both) of them might not be finished yet?
If statement 2 relies on statement1 being finished, there are just two outcomes: eitehr statement1 finished right NOW and everything proceeeds fine,
or statement1 didn't finish yet, and thus staement 2 is going to fail.

function add(getX,getY,cb) {
	var x, y;
	getX( function(xVal){
		x = xVal;
		// both are ready?
		if (y != undefined) {
			cb( x + y );	// send along sum
		}
	} );
	getY( function(yVal){
		y = yVal;
		// both are ready?
		if (x != undefined) {
			cb( x + y );	// send along sum
		}
	} );
}

// `fetchX()` and `fetchY()` are sync or async
// functions
add( fetchX, fetchY, function(sum){
	console.log( sum ); // that was easy, huh?
} );


When the ugliness is undeniable, theres something very important to notice about this async pattern.
in that snippet, we treated x and y as future values,a nd we express an operation add(...) that from the outside
does not care whether x or y or both are available right away or not. In other words, it noramlizes the now and later,
such taht we can rely on a predictable outcome of the add(...) operation

By using an add.... that is temporally consistent -- it behaves the same acrross now and later itmes 
the async code is much easier to reason about.

To put it more plainly: to consistently handle both now and later, we both make both of them later: all operations become async,

Of course, th is rough callbacks based approach laeaves much to be desired. its just a first tiny step twoards realizing theb enfits
of reasoning baout future values wihtout worrying about the time aspect of hwne its available or not.

Promise value:
We'll definitely go into more detail about promises later in the chapter.
function add(xPromise,yPromise) {
	// `Promise.all([ .. ])` takes an array of promises,
	// and returns a new promise that waits on them
	// all to finish
	return Promise.all( [xPromise, yPromise] )

	// when that promise is resolved, let's take the
	// received `X` and `Y` values and add them together.
	.then( function(values){
		// `values` is an array of the messages from the
		// previously resolved promises
		return values[0] + values[1];
	} );
}

// `fetchX()` and `fetchY()` return promises for
// their respective values, which may be ready
// *now* or *later*.
add( fetchX(), fetchY() )

// we get a promise back for the sum of those
// two numbers.
// now we chain-call `then(..)` to wait for the
// resolution of that returned promise.
.then( function(sum){
	console.log( sum ); // that was easier!
} );


There are two layers of promises in this snippet.
fetchX() and fetvchY() are called irectly, and the values they return (promises) are passed into add(....)
the underlyuing values those promises represent may be ready now or later, but each promise noramlizes the bhavior to be the same regardless. We reason about X and Y values in a timer independent way.
They are future values.

The second layer is the promise that addd(...) creates (vvia Promise.all) and returns, which we wait on by calling then(...) when the add(...)
operation completes, our sum future value is ready and we can print it out. WE hid inside of add(..) the logic for waiting ont he x and y future values.


Note: Inside add(..), the Promise.all([ .. ]) call creates a promise (which is waiting on promiseX and promiseY to resolve). The chained call to .then(..) creates another promise, which
 the return values[0] + values[1] line immediately resolves (with the result of the addition). Thus, the then(..) call we chain off the end of the add(..) call -- at the end of the snippet
  -- is actually operating on that second promise returned, rather than the first one created by Promise.all([ .. ]). Also, though we are not chaining off the end of that second then(..), it too has created another promise, had we chosen to observe/use it. This Promise chaining stuff will be explained in much greater detail later in this chapter.



Just like with cheeseburger orders, it's possible that the resolution of a Promise is rejection instead of fulfillment. Unlike a fulfilled Promise, where the value is always programmatic, a rejection value -- commonly called a "rejection reason" -- can either be set directly by the program logic, or it can result implicitly from a runtime exception.

With Promises, the then(..) call can actually take two functions, the first for fulfillment (as shown earlier), and the second for rejection:

add( fetchX(), fetchY() )
.then(
	// fulfillment handler
	function(sum) {
		console.log( sum );
	},
	// rejection handler
	function(err) {
		console.error( err ); // bummer!
	}
);


If something went wrong with getting x or y, or something somehow failed during the addition, the promise that add(...) returns is rejected, and the second callback error handler
passed to the then(...) will receive the rejection value from the promise.

Because promises encapsluate the time-dependent state -- waiting on the fulfillment or rejection of the underlying value -- from the outside, the promise itself is time-independent, and thus promises can becomposed (combined in predictable ways regardless of the timing or outcome underneat.)

Moreover, once a promise is resolved, it stays that way forever -- itbecomes an immutable value ant that point -- and can be observed as many times as necessary.

add( fetchX(), fetchY() )
.then(
	// fulfillment handler
	function(sum) {
		console.log( sum );
	},
	// rejection handler
	function(err) {
		console.error( err ); // bummer!
	}
);
If something went wrong getting X or Y, or something somehow failed during the addition, the promise that add(..) returns is rejected, and the second callback error handler passed to then(..) will receive the rejection value from the promise.

Because Promises encapsulate the time-dependent state -- waiting on the fulfillment or rejection of the underlying value -- from the outside, the Promise itself is time-independent, and thus Promises can be composed (combined) in predictable ways regardless of the timing or outcome underneath.

Moreover, once a Promise is resolved, it stays that way forever -- it becomes an immutable value at that point -- and can then be observed as many times as necessary.

Note: Because a Promise is externally immutable once resolved, it's now safe to pass that value around to any party and know that it cannot be modified accidentally or maliciously. This is especially true in relation to multiple parties observing the resolution of a Promise. It is not possible for one party to affect another party's ability to observe Promise resolution. Immutability may sound like an academic topic, but it's actually one of the most fundamental and important aspects of Promise design, and shouldn't be casually passed over.

That's one of the most powerful and important concepts to understand about Promises. With a fair amount of work, you could ad hoc create the same effects with nothing but ugly callback composition, but that's not really an effective strategy, especially because you have to do it over and over again.

Promises are an easily repeatable mechanism for encapsulating and composing future values.



Completion Event:
As we just saw, an individual promise behaves as a future value. But there's anohte rway to think of the resolution as a promise: as a flow-control mechanism -- a temporal this th en that for two or more steps in an asynchronous task.
Lets imagine the calling a function foo(...) to perform some tak. We don't nkow about any of its details, nor do we care. It may complete the task right awya, or it may take awhile.
We just simply need to know when foo() finishes so that we3 can move on to our next task. In other words, we'd like a away to be notified of foo()'s completeion so that we can continue.

In typical javascript fashion, you need to listen for a notifcation, you'd likely think of that in terms of events.
So we could reframe our need for notification as a need to listen for a completion.

Note: Whether you call it a "completion event" or a "continuation event" depends on your perspective. Is the focus more on what happens with foo(..), or what happens after foo(..) finishes? Both perspectives are accurate and useful.
 The event notification tells us that foo(..) has completed, but also that it's OK to continue with the next step. Indeed, the callback you pass to be called for the event notification is itself what we've previously called a continuation. 
 Because completion event is a bit more focused on the foo(..), which more has our attention at present, we slightly favor completion event for the rest of this text.

foo(x) {
	// start doing something that could take a while
}

foo( 42 )

on (foo "completion") {
	// now we can do the next step!
}

on (foo "error") {
	// oops, something went wrong in `foo(..)`
}



WE call foo(...) and then we set up two event listeners, one for "completion" and one for "error"
-the two poossible final outocmes of the foo(*...) call. In essence, foo(...) doesn't even appear to be aware that the calling code
has subscribed to these events, which makes for a very nice seeparatino of concerns.

Unfortunately, such code would require some "magic" of the JS environment that doens't exist
and would likely be a bitimpractical
function foo(x) {
	// start doing something that could take a while

	// make a `listener` event notification
	// capability to return

	return listener;
}

var evt = foo( 42 );

evt.on( "completion", function(){
	// now we can do the next step!
} );

evt.on( "failure", function(err){
	// oops, something went wrong in `foo(..)`
} );

foo(..) expressly creates an event subscription capability to return back, and the calling code receives and registers the two event handlers against it.

The inversion from normal callback-oriented code should be obvious, and it's intentional. Instead of passing the callbacks to foo(..), it returns an event capability we call evt, which receives the callbacks.

But if you recall from Chapter 2, callbacks themselves represent an inversion of control. So inverting the callback pattern is actually an inversion of inversion, or an uninversion of control -- restoring control back to the calling code where we wanted it to be in the first place.

One important benefit is that multiple separate parts of the code can be given the event listening capability, and they can all independently be notified of when foo(..) completes to perform subsequent steps after its completion:


var evt = foo( 42 );

// let `bar(..)` listen to `foo(..)`'s completion
bar( evt );

// also, let `baz(..)` listen to `foo(..)`'s completion
baz( evt );

Uninversion of control enables a nicer separation of concerns, where bar(..) and baz(..) don't need to be involved in how foo(..) is called. Similarly, foo(..) doesn't need to know or care that bar(..) and baz(..) exist or are waiting to be notified when foo(..) completes.

Essentially, this evt object is a neutral third-party negotiation between the separate concerns.


Promise "Events"
As yo umay ahgve guessed by now, the et even listening capability 8is an analogy for ap romise
In a Promise-based approach, the previous snippet would have foo(..) creating and returning a Promise instance, and that promise would then be passed to bar(..) and baz(..).

Note: The Promise resolution "events" we listen for aren't strictly events (though they certainly behave like events for these purposes), and they're not typically called "completion" or "error". Instead, we use then(..) to register a "then" event. Or perhaps more precisely, then(..) registers "fulfillment" and/or "rejection" event(s), though we don't see those terms used explicitly in the code.

function foo(x) {
	// start doing something that could take a while

	// construct and return a promise
	return new Promise( function(resolve,reject){
		// eventually, call `resolve(..)` or `reject(..)`,
		// which are the resolution callbacks for
		// the promise.
	} );
}

var p = foo( 42 );

bar( p );

baz( p );

Note: The pattern shown with new Promise( function(..){ .. } ) is generally called the "revealing constructor". The function passed in is executed immediately (not async deferred, as callbacks to then(..) are), and it's provided two parameters, which in this case we've named resolve and reject. These are the resolution functions for the promise. resolve(..) generally signals fulfillment, and reject(..) signals rejection.

You can probably guess what the internals of bar(..) and baz(..) might look like:


function bar(fooPromise) {
	// listen for `foo(..)` to complete
	fooPromise.then(
		function(){
			// `foo(..)` has now finished, so
			// do `bar(..)`'s task
		},
		function(){
			// oops, something went wrong in `foo(..)`
		}
	);
}

// ditto for `baz(..)

Another way to approach this is:
function bar() {
	// `foo(..)` has definitely finished, so
	// do `bar(..)`'s task
}

function oopsBar() {
	// oops, something went wrong in `foo(..)`,
	// so `bar(..)` didn't run
}

// ditto for `baz()` and `oopsBaz()`

var p = foo( 42 );

p.then( bar, oopsBar );

p.then( baz, oopsBaz );

Note: If you've seen Promise-based coding before, you might be tempted to believe that the last two lines of that code could be written as p.then( .. ).then( .. ), using chaining, rather than p.then(..); p.then(..). That would have an entirely different behavior, so be careful! The difference might not be clear right now, but it's actually a different async pattern than we've seen thus far: splitting/forking. 

Instead of passing the p promise to bar(..) and baz(..), we use the promise to control when bar(..) and baz(..) will get executed, if ever. The primary difference is in the error handling.

In the first snippet's approach, bar(..) is called regardless of whether foo(..) succeeds or fails, and it handles its own fallback logic if it's notified that foo(..) failed. The same is true for baz(..), obviously.

In the second snippet, bar(..) only gets called if foo(..) succeeds, and otherwise oopsBar(..) gets called. Ditto for baz(..).

Neither approach is correct per se. There will be cases where one is preferred over the other.

In either case, the promise p that comes back from foo(..) is used to control what happens next.

Moreover, the fact that both snippets end up calling then(..) twice against the same promise p illustrates the point made earlier, which is that Promises (once resolved) retain their same resolution (fulfillment or rejection) forever, and can subsequently be observed as many times as necessary.

Whenever p is resolved, the next step will always be the same, both now and later.


Thenable Duck typing
In Promises-land, an important detail is how to know for sure if some value is a genuine Promise or not. Or more directly, is it a value that will behave like a Promise?

Given that Promises are constructed by the new Promise(..) syntax, you might think that p instanceof Promise would be an acceptable check. But unfortunately, there are a number of reasons that's not totally sufficient.

Mainly, you can receive a Promise value from another browser window (iframe, etc.), which would have its own Promise different from the one in the current window/frame, and that check would fail to identify the Promise instance.

Moreover, a library or framework may choose to vend its own Promises and not use the native ES6 Promise implementation to do so. In fact, you may very well be using Promises with libraries in older browsers that have no Promise at all.

When we discuss Promise resolution processes later in this chapter, it will become more obvious why a non-genuine-but-Promise-like value would still be very important to be able to recognize and assimilate. But for now, just take my word for it that it's a critical piece of the puzzle.

As such, it was decided that the way to recognize a Promise (or something that behaves like a Promise) would be to define something called a "thenable" as any object or function which has a then(..) method on it. It is assumed that any such value is a Promise-conforming thenable.

The general term for "type checks" that make assumptions about a value's "type" based on its shape (what properties are present) is called "duck typing" -- "If it looks like a duck, and quacks like a duck, it must be a duck" (see the Types & Grammar title of this book series). So the duck typing check for a thenable would roughly be:

if (
	p !== null &&
	(
		typeof p === "object" ||
		typeof p === "function"
	) &&
	typeof p.then === "function"
) {
	// assume it's a thenable!
}
else {
	// not a thenable
}

Yuck! Setting aside the fact that this logic is a bit ugly to implement in various places, there's something deeper and more troubling going on.

If you try to fulfill a Promise with any object/function value that happens to have a then(..) function on it, but you weren't intending it to be treated as a Promise/thenable, you're out of luck, because it will automatically be recognized as thenable and treated with special rules (see later in the chapter).

This is even true if you didn't realize the value has a then(..) on it. For example:

var o = { then: function(){} };

// make `v` be `[[Prototype]]`-linked to `o`
var v = Object.create( o );

v.someStuff = "cool";
v.otherStuff = "not so cool";

v.hasOwnProperty( "then" );		

v doesn't look like a Promise or thenable at all. It's just a plain object with some properties on it. You're probably just intending to send that value around like any other object.

But unknown to you, v is also [[Prototype]]-linked (see the this & Object Prototypes title of this book series) to another object o, which happens to have a then(..) on it. So the thenable duck typing checks will think and assume v is a thenable. Uh oh.

It doesn't even need to be something as directly intentional as that:


Object.prototype.then = function(){};
Array.prototype.then = function(){};

var v1 = { hello: "world" };
var v2 = [ "Hello", "World" ];

Both v1 and v2 will be assumed to be thenables. You can't control or predict if any other code accidentally or maliciously adds then(..) to Object.prototype, Array.prototype, or any of the other native prototypes. And if what's specified is a function that doesn't call either of its parameters as callbacks, then any Promise resolved with such a value will just silently hang forever! Crazy.

Sound implausible or unlikely? Perhaps.

But keep in mind that there were several well-known non-Promise libraries preexisting in the community prior to ES6 that happened to already have a method on them called then(..). Some of those libraries chose to rename their own methods to avoid collision (that sucks!). Others have simply been relegated to the unfortunate status of "incompatible with Promise-based coding" in reward for their inability to change to get out of the way.

The standards decision to hijack the previously nonreserved -- and completely general-purpose sounding -- then property name means that no value (or any of its delegates), either past, present, or future, can have a then(..) function present, either on purpose or by accident, or that value will be confused for a thenable in Promises systems, which will probably create bugs that are really hard to track down.

Warning: I do not like how we ended up with duck typing of thenables for Promise recognition. There were other options, such as "branding" or even "anti-branding"; what we got seems like a worst-case compromise. But it's not all doom and gloom. Thenable duck typing can be helpful, as we'll see later. Just beware that thenable duck typing can be hazardous if it incorrectly identifies something as a Promise that isn't.

Promise Trust
We've now seen two strong analogies that explain different aspects of what Promises can do for our async code. But if we stop there, we've missed perhaps the single most important characteristic that the Promise pattern establishes: trust.

Whereas the future values and completion events analogies play out explicitly in the code patterns we've explored, it won't be entirely obvious why or how Promises are designed to solve all of the inversion of control trust issues we laid out in the "Trust Issues" section of Chapter 2. But with a little digging, we can uncover some important guarantees that restore the confidence in async coding that Chapter 2 tore down!

Let's start by reviewing the trust issues with callbacks-only coding. When you pass a callback to a utility foo(..), it might:

Call the callback too early
Call the callback too late (or never)
Call the callback too few or too many times
Fail to pass along any necessary environment/parameters
Swallow any errors/exceptions that may happen
The characteristics of Promises are intentionally designed to provide useful, repeatable answers to all these concerns.


Calling Too Early
Primarily, this is a concern of whether code can introduce Zalgo-like effects (see Chapter 2), where sometimes a task finishes synchronously and sometimes asynchronously, which can lead to race conditions.

Promises by definition cannot be susceptible to this concern, because even an immediately fulfilled Promise (like new Promise(function(resolve){ resolve(42); })) cannot be observed synchronously.

That is, when you call then(..) on a Promise, even if that Promise was already resolved, the callback you provide to then(..) will always be called asynchronously (for more on this, refer back to "Jobs" in Chapter 1).

No more need to insert your own setTimeout(..,0) hacks. Promises prevent Zalgo automatically.

Calling Too Late
Similar to the previous point, a Promise's then(..) registered observation callbacks are automatically scheduled when either resolve(..) or reject(..) are called by the Promise creation capability. Those scheduled callbacks will predictably be fired at the next asynchronous moment (see "Jobs" in Chapter 1).

It's not possible for synchronous observation, so it's not possible for a synchronous chain of tasks to run in such a way to in effect "delay" another callback from happening as expected. That is, when a Promise is resolved, all then(..) registered callbacks on it will be called, in order, immediately at the next asynchronous opportunity (again, see "Jobs" in Chapter 1), and nothing that happens inside of one of those callbacks can affect/delay the calling of the other callbacks.

For example:

p.then( function(){
	p.then( function(){
		console.log( "C" );
	} );
	console.log( "A" );
} );
p.then( function(){
	console.log( "B" );
} );
// A B C


romise Scheduling Quirks
It's important to note, though, that there are lots of nuances of scheduling where the relative ordering between callbacks chained off two separate Promises is not reliably predictable.

If two promises p1 and p2 are both already resolved, it should be true that p1.then(..); p2.then(..) would end up calling the callback(s) for p1 before the ones for p2. But there are subtle cases where that might not be true, such as the following:

var p3 = new Promise( function(resolve,reject){
	resolve( "B" );
} );

var p1 = new Promise( function(resolve,reject){
	resolve( p3 );
} );

var p2 = new Promise( function(resolve,reject){
	resolve( "A" );
} );

p1.then( function(v){
	console.log( v );
} );

p2.then( function(v){
	console.log( v );
} );

// A B  <-- not  B A  as you might expect

We'll cover this more later, but as you can see, p1 is resolved not with an immediate value, but with another promise p3 which is itself resolved with the value "B". The specified behavior is to unwrap p3 into p1, but asynchronously, so p1's callback(s) are behind p2's callback(s) in the asynchronous Job queue (see Chapter 1).

To avoid such nuanced nightmares, you should never rely on anything about the ordering/scheduling of callbacks across Promises. In fact, a good practice is not to code in such a way where the ordering of multiple callbacks matters at all. Avoid that if you can.





Never Calling the Callback
This is a very common concern. It's addressable in several ways with Promises.

First, nothing (not even a JS error) can prevent a Promise from notifying you of its resolution (if it's resolved). If you register both fulfillment and rejection callbacks for a Promise, and the Promise gets resolved, one of the two callbacks will always be called.

Of course, if your callbacks themselves have JS errors, you may not see the outcome you expect, but the callback will in fact have been called. We'll cover later how to be notified of an error in your callback, because even those don't get swallowed.

But what if the Promise itself never gets resolved either way? Even that is a condition that Promises provide an answer for, using a higher level abstraction called a "race":


// a utility for timing out a Promise
function timeoutPromise(delay) {
	return new Promise( function(resolve,reject){
		setTimeout( function(){
			reject( "Timeout!" );
		}, delay );
	} );
}

// setup a timeout for `foo()`
Promise.race( [
	foo(),					// attempt `foo()`
	timeoutPromise( 3000 )	// give it 3 seconds
] )
.then(
	function(){
		// `foo(..)` fulfilled in time!
	},
	function(err){
		// either `foo()` rejected, or it just
		// didn't finish in time, so inspect
		// `err` to know which
	}
);

Calling Too Few or Too Many Times
By definition, one is the appropriate number of times for the callback to be called. The "too few" case would be zero calls, which is the same as the "never" case we just examined.

The "too many" case is easy to explain. Promises are defined so that they can only be resolved once. If for some reason the Promise creation code tries to call resolve(..) or reject(..) multiple times, or tries to call both, the Promise will accept only the first resolution, and will silently ignore any subsequent attempts.



ecause a Promise can only be resolved once, any then(..) registered callbacks will only ever be called once (each).

Of course, if you register the same callback more than once, (e.g., p.then(f); p.then(f);), it'll be called as many times as it was registered. The guarantee that a response function is called only once does not prevent you from shooting yourself in the foot.


Failing to Pass Along Any Parameters/Environment
Promises can have, at most, one resolution value (fulfillment or rejection).

If you don't explicitly resolve with a value either way, the value is undefined, as is typical in JS. But whatever the value, it will always be passed to all registered (and appropriate: fulfillment or rejection) callbacks, either now or in the future.

Something to be aware of: If you call resolve(..) or reject(..) with multiple parameters, all subsequent parameters beyond the first will be silently ignored. Although that might seem a violation of the guarantee we just described, it's not exactly, because it constitutes an invalid usage of the Promise mechanism. Other invalid usages of the API (such as calling resolve(..) multiple times) are similarly protected, so the Promise behavior here is consistent (if not a tiny bit frustrating).

If you want to pass along multiple values, you must wrap them in another single value that you pass, such as an array or an object.

As for environment, functions in JS always retain their closure of the scope in which they're defined (see the Scope & Closures title of this series), so they of course would continue to have access to whatever surrounding state you provide. Of course, the same is true of callbacks-only design, so this isn't a specific augmentation of benefit from Promises -- but it's a guarantee we can rely on nonetheless.

Swallowing Any Errors/Exceptions
In the base sense, this is a restatement of the previous point. If you reject a Promise with a reason (aka error message), that value is passed to the rejection callback(s).

But there's something much bigger at play here. If at any point in the creation of a Promise, or in the observation of its resolution, a JS exception error occurs, such as a TypeError or ReferenceError, that exception will be caught, and it will force the Promise in question to become rejected.


var p = new Promise( function(resolve,reject){
	foo.bar();	// `foo` is not defined, so error!
	resolve( 42 );	// never gets here :(
} );

p.then(
	function fulfilled(){
		// never gets here :(
	},
	function rejected(err){
		// `err` will be a `TypeError` exception object
		// from the `foo.bar()` line.
	}
);

The JS exception that occurs from foo.bar() becomes a Promise rejection that you can catch and respond to.

This is an important detail, because it effectively solves another potential Zalgo moment, which is that errors could create a synchronous reaction whereas nonerrors would be asynchronous. Promises turn even JS exceptions into asynchronous behavior, thereby reducing the race condition chances greatly.

But what happens if a Promise is fulfilled, but there's a JS exception error during the observation (in a then(..) registered callback)? Even those aren't lost, but you may find how they're handled a bit surprising, until you dig in a little deeper:

var p = new Promise( function(resolve,reject){
	resolve( 42 );
} );

p.then(
	function fulfilled(msg){
		foo.bar();
		console.log( msg );	// never gets here :(
	},
	function rejected(err){
		// never gets here either :(
	}
);

Wait, that makes it seem like the exception from foo.bar() really did get swallowed. Never fear, it didn't. But something deeper is wrong, which is that we've failed to listen for it. The p.then(..) call itself returns another promise, and it's that promise that will be rejected with the TypeError exception.

Why couldn't it just call the error handler we have defined there? Seems like a logical behavior on the surface. But it would violate the fundamental principle that Promises are immutable once resolved. p was already fulfilled to the value 42, so it can't later be changed to a rejection just because there's an error in observing p's resolution.

Besides the principle violation, such behavior could wreak havoc, if say there were multiple then(..) registered callbacks on the promise p, because some would get called and others wouldn't, and it would be very opaque as to why.

Trustable Promise?
There's one last detail to examine to establish trust based on the Promise pattern.

You've no doubt noticed that Promises don't get rid of callbacks at all. They just change where the callback is passed to. Instead of passing a callback to foo(..), we get something (ostensibly a genuine Promise) back from foo(..), and we pass the callback to that something instead.

But why would this be any more trustable than just callbacks alone? How can we be sure the something we get back is in fact a trustable Promise? Isn't it basically all just a house of cards where we can trust only because we already trusted?

One of the most important, but often overlooked, details of Promises is that they have a solution to this issue as well. Included with the native ES6 Promise implementation is Promise.resolve(..).

If you pass an immediate, non-Promise, non-thenable value to Promise.resolve(..), you get a promise that's fulfilled with that value. In other words, these two promises p1 and p2 will behave basically identically:

var p1 = new Promise( function(resolve,reject){
	resolve( 42 );
} );

var p2 = Promise.resolve( 42 );


But if you pass a genuine Promise to Promise.resolve(..), you just get the same promise back:
var p1 = Promise.resolve( 42 );

var p2 = Promise.resolve( p1 );

p1 === p2; // true

var p = {
	then: function(cb) {
		cb( 42 );
	}
};

// this works OK, but only by good fortune
p
.then(
	function fulfilled(val){
		console.log( val ); // 42
	},
	function rejected(err){
		// never gets here
	}
);

rust Built
Hopefully the previous discussion now fully "resolves" (pun intended) in your mind why the Promise is trustable, and more importantly, why that trust is so critical in building robust, maintainable software.

Can you write async code in JS without trust? Of course you can. We JS developers have been coding async with nothing but callbacks for nearly two decades.

But once you start questioning just how much you can trust the mechanisms you build upon to actually be predictable and reliable, you start to realize callbacks have a pretty shaky trust foundation.

Promises are a pattern that augments callbacks with trustable semantics, so that the behavior is more reason-able and more reliable. By uninverting the inversion of control of callbacks, we place the control with a trustable system (Promises) that was designed specifically to bring sanity to our async.

Chain Flow
We've hinted at this a couple of times already, but Promises are not just a mechanism for a single-step this-then-that sort of operation. That's the building block, of course, but it turns out we can string multiple Promises together to represent a sequence of async steps.

The key to making this work is built on two behaviors intrinsic to Promises:

Every time you call then(..) on a Promise, it creates and returns a new Promise, which we can chain with.
Whatever value you return from the then(..) call's fulfillment callback (the first parameter) is automatically set as the fulfillment of the chained Promise (from the first point).
Let's first illustrate what that means, and then we'll derive how that helps us create async sequences of flow control. Consider the following:

var p = Promise.resolve( 21 );

var p2 = p.then( function(v){
	console.log( v );	// 21

	// fulfill `p2` with value `42`
	return v * 2;
} );

// chain off `p2`
p2.then( function(v){
	console.log( v );	// 42
} );

By returning v * 2 (i.e., 42), we fulfill the p2 promise that the first then(..) call created and returned. When p2's then(..) call runs, it's receiving the fulfillment from the return v * 2 statement. Of course, p2.then(..) creates yet another promise, which we could have stored in a p3 variable.

But it's a little annoying to have to create an intermediate variable p2 (or p3, etc.). Thankfully, we can easily just chain these together:

var p = Promise.resolve( 21 );

p
.then( function(v){
	console.log( v );	// 21

	// fulfill the chained promise with value `42`
	return v * 2;
} )
// here's the chained promise
.then( function(v){
	console.log( v );	// 42
} );

So now the first then(..) is the first step in an async sequence, and the second then(..) is the second step. This could keep going for as long as you needed it to extend. Just keep chaining off a previous then(..) with each automatically created Promise.

But there's something missing here. What if we want step 2 to wait for step 1 to do something asynchronous? We're using an immediate return statement, which immediately fulfills the chained promise.

The key to making a Promise sequence truly async capable at every step is to recall how Promise.resolve(..) operates when what you pass to it is a Promise or thenable instead of a final value. Promise.resolve(..) directly returns a received genuine Promise, or it unwraps the value of a received thenable -- and keeps going recursively while it keeps unwrapping thenables.

The same sort of unwrapping happens if you return a thenable or Promise from the fulfillment (or rejection) handler. Consider:


var p = Promise.resolve( 21 );

p.then( function(v){
	console.log( v );	// 21

	// create a promise and return it
	return new Promise( function(resolve,reject){
		// fulfill with value `42`
		resolve( v * 2 );
	} );
} )
.then( function(v){
	console.log( v );	// 42
} );


var p = Promise.resolve( 21 );

p.then( function(v){
	console.log( v );	// 21

	// create a promise to return
	return new Promise( function(resolve,reject){
		// introduce asynchrony!
		setTimeout( function(){
			// fulfill with value `42`
			resolve( v * 2 );
		}, 100 );
	} );
} )
.then( function(v){
	// runs after the 100ms delay in the previous step
	console.log( v );	// 42
} );

That's incredibly powerful! Now we can construct a sequence of however many async steps we want, and each step can delay the next step (or not!), as necessary.

Of course, the value passing from step to step in these examples is optional. If you don't return an explicit value, an implicit undefined is assumed, and the promises still chain together the same way. Each Promise resolution is thus just a signal to proceed to the next step.

To further the chain illustration, let's generalize a delay-Promise creation (without resolution messages) into a utility we can reuse for multiple steps:


function delay(time) {
	return new Promise( function(resolve,reject){
		setTimeout( resolve, time );
	} );
}

delay( 100 ) // step 1
.then( function STEP2(){
	console.log( "step 2 (after 100ms)" );
	return delay( 200 );
} )
.then( function STEP3(){
	console.log( "step 3 (after another 200ms)" );
} )
.then( function STEP4(){
	console.log( "step 4 (next Job)" );
	return delay( 50 );
} )
.then( function STEP5(){
	console.log( "step 5 (after another 50ms)" );
} )
...

Calling delay(200) creates a promise that will fulfill in 200ms, and then we return that from the first then(..) fulfillment callback, which causes the second then(..)'s promise to wait on that 200ms promise.

Note: As described, technically there are two promises in that interchange: the 200ms-delay promise and the chained promise that the second then(..) chains from. But you may find it easier to mentally combine these two promises together, because the Promise mechanism automatically merges their states for you. In that respect, you could think of return delay(200) as creating a promise that replaces the earlier-returned chained promise.

To be honest, though, sequences of delays with no message passing isn't a terribly useful example of Promise flow control. Let's look at a scenario that's a little more practical.

Instead of timers, let's consider making Ajax requests:

// assume an `ajax( {url}, {callback} )` utility

// Promise-aware ajax
function request(url) {
	return new Promise( function(resolve,reject){
		// the `ajax(..)` callback should be our
		// promise's `resolve(..)` function
		ajax( url, resolve );
	} );
}

request( "http://some.url.1/" )
.then( function(response1){
	return request( "http://some.url.2/?v=" + response1 );
} )
.then( function(response2){
	console.log( response2 );
} );


Note: Developers commonly encounter situations in which they want to do Promise-aware async flow control with utilities that are not themselves Promise-enabled (like ajax(..) here, which expects a callback). Although the native ES6 Promise mechanism doesn't automatically solve this pattern for us, practically all Promise libraries do. They usually call this process "lifting" or "promisifying" or some variation thereof. We'll come back to this technique later.

Using the Promise-returning request(..), we create the first step in our chain implicitly by calling it with the first URL, and chain off that returned promise with the first then(..).

Once response1 comes back, we use that value to construct a second URL, and make a second request(..) call. That second request(..) promise is returned so that the third step in our async flow control waits for that Ajax call to complete. Finally, we print response2 once it returns.


// step 1:
request( "http://some.url.1/" )

// step 2:
.then( function(response1){
	foo.bar(); // undefined, error!

	// never gets here
	return request( "http://some.url.2/?v=" + response1 );
} )

// step 3:
.then(
	function fulfilled(response2){
		// never gets here
	},
	// rejection handler to catch the error
	function rejected(err){
		console.log( err );	// `TypeError` from `foo.bar()` error
		return 42;
	}
)

// step 4:
.then( function(msg){
	console.log( msg );		// 42
} );

When the error occurs in step 2, the rejection handler in step 3 catches it. The return value (42 in this snippet), if any, from that rejection handler fulfills the promise for the next step (4), such that the chain is now back in a fulfillment state.

Note: As we discussed earlier, when returning a promise from a fulfillment handler, it's unwrapped and can delay the next step. That's also true for returning promises from rejection handlers, such that if the return 42 in step 3 instead returned a promise, that promise could delay step 4. A thrown exception inside either the fulfillment or rejection handler of a then(..) call causes the next (chained) promise to be immediately rejected with that exception.

var p = new Promise( function(resolve,reject){
	reject( "Oops" );
} );

var p2 = p.then(
	function fulfilled(){
		// never gets here
	}
	// assumed rejection handler, if omitted or
	// any other non-function value passed
	// function(err) {
	//     throw err;
	// }
);

As you can see, the assumed rejection handler simply rethrows the error, which ends up forcing p2 (the chained promise) to reject with the same error reason. In essence, this allows the error to continue propagating along a Promise chain until an explicitly defined rejection handler is encountered.

Note: We'll cover more details of error handling with Promises a little later, because there are other nuanced details to be concerned about.

If a proper valid function is not passed as the fulfillment handler parameter to then(..), there's also a default handler substituted:

var p = Promise.resolve( 42 );

p.then(
	// assumed fulfillment handler, if omitted or
	// any other non-function value passed
	// function(v) {
	//     return v;
	// }
	null,
	function rejected(err){
		// never gets here
	}
);

The JS exception that occurs from foo.bar() becomes a Promise rejection that you can catch and respond to.

This is an important detail, because it effectively solves another potential Zalgo moment, which is that errors could create a synchronous reaction whereas nonerrors would be asynchronous. Promises turn even JS exceptions into asynchronous behavior, thereby reducing the race condition chances greatly.

But what happens if a Promise is fulfilled, but there's a JS exception error during the observation (in a then(..) registered callback)? Even those aren't lost, but you may find how they're handled a bit surprising, until you dig in a little deeper:

var p = new Promise( function(resolve,reject){
	resolve( 42 );
} );

p.then(
	function fulfilled(msg){
		foo.bar();
		console.log( msg );	// never gets here :(
	},
	function rejected(err){
		// never gets here either :(
	}
);

Wait, that makes it seem like the exception from foo.bar() really did get swallowed. Never fear, it didn't. But something deeper is wrong, which is that we've failed to listen for it. The p.then(..) call itself returns another promise, and it's that promise that will be rejected with the TypeError exception.

Why couldn't it just call the error handler we have defined there? Seems like a logical behavior on the surface. But it would violate the fundamental principle that Promises are immutable once resolved. p was already fulfilled to the value 42, so it can't later be changed to a rejection just because there's an error in observing p's resolution.

Besides the principle violation, such behavior could wreak havoc, if say there were multiple then(..) registered callbacks on the promise p, because some would get called and others wouldn't, and it would be very opaque as to why.

Trustable Promise?
There's one last detail to examine to establish trust based on the Promise pattern.

You've no doubt noticed that Promises don't get rid of callbacks at all. They just change where the callback is passed to. Instead of passing a callback to foo(..), we get something (ostensibly a genuine Promise) back from foo(..), and we pass the callback to that something instead.

But why would this be any more trustable than just callbacks alone? How can we be sure the something we get back is in fact a trustable Promise? Isn't it basically all just a house of cards where we can trust only because we already trusted?

One of the most important, but often overlooked, details of Promises is that they have a solution to this issue as well. Included with the native ES6 Promise implementation is Promise.resolve(..).

If you pass an immediate, non-Promise, non-thenable value to Promise.resolve(..), you get a promise that's fulfilled with that value. In other words, these two promises p1 and p2 will behave basically identically:

var p1 = new Promise( function(resolve,reject){
	resolve( 42 );
} );

var p2 = Promise.resolve( 42 );

var p1 = Promise.resolve( 42 );

var p2 = Promise.resolve( p1 );

p1 === p2; // true



Even more importantly, if you pass a non-Promise thenable value to Promise.resolve(..), it will attempt to unwrap that value, and the unwrapping will keep going until a concrete final non-Promise-like value is extracted.

Recall our previous discussion of thenables?

Consider:

var p = {
	then: function(cb) {
		cb( 42 );
	}
};

// this works OK, but only by good fortune
p
.then(
	function fulfilled(val){
		console.log( val ); // 42
	},
	function rejected(err){
		// never gets here
	}
);

var p = {
	then: function(cb,errcb) {
		cb( 42 );
		errcb( "evil laugh" );
	}
};

p
.then(
	function fulfilled(val){
		console.log( val ); // 42
	},
	function rejected(err){
		// oops, shouldn't have run
		console.log( err ); // evil laugh
	}
);

This p is a thenable but it's not so well behaved of a promise. Is it malicious? Or is it just ignorant of how Promises should work? It doesn't really matter, to be honest. In either case, it's not trustable as is.

Nonetheless, we can pass either of these versions of p to Promise.resolve(..), and we'll get the normalized, safe result we'd expect:
Promise.resolve( p )
.then(
	function fulfilled(val){
		console.log( val ); // 42
	},
	function rejected(err){
		// never gets here
	}
);

Promise.resolve(..) will accept any thenable, and will unwrap it to its non-thenable value. But you get back from Promise.resolve(..) a real, genuine Promise in its place, one that you can trust. If what you passed in is already a genuine Promise, you just get it right back, so there's no downside at all to filtering through Promise.resolve(..) to gain trust.

So let's say we're calling a foo(..) utility and we're not sure we can trust its return value to be a well-behaving Promise, but we know it's at least a thenable. Promise.resolve(..) will give us a trustable Promise wrapper to chain off of:


// don't just do this:
foo( 42 )
.then( function(v){
	console.log( v );
} );

// instead, do this:
Promise.resolve( foo( 42 ) )
.then( function(v){
	console.log( v );
} );

Note: Another beneficial side effect of wrapping Promise.resolve(..) around any function's return value (thenable or not) is that it's an easy way to normalize that function call into a well-behaving async task. If foo(42) returns an immediate value sometimes, or a Promise other times, Promise.resolve( foo(42) ) makes sure it's always a Promise result. And avoiding Zalgo makes for much better code.

Trust Built
Hopefully the previous discussion now fully "resolves" (pun intended) in your mind why the Promise is trustable, and more importantly, why that trust is so critical in building robust, maintainable software.

Can you write async code in JS without trust? Of course you can. We JS developers have been coding async with nothing but callbacks for nearly two decades.

But once you start questioning just how much you can trust the mechanisms you build upon to actually be predictable and reliable, you start to realize callbacks have a pretty shaky trust foundation.

Promises are a pattern that augments callbacks with trustable semantics, so that the behavior is more reason-able and more reliable. By uninverting the inversion of control of callbacks, we place the control with a trustable system (Promises) that was designed specifically to bring sanity to our async.

Chain Flow
We've hinted at this a couple of times already, but Promises are not just a mechanism for a single-step this-then-that sort of operation. That's the building block, of course, but it turns out we can string multiple Promises together to represent a sequence of async steps.

The key to making this work is built on two behaviors intrinsic to Promises:

Every time you call then(..) on a Promise, it creates and returns a new Promise, which we can chain with.
Whatever value you return from the then(..) call's fulfillment callback (the first parameter) is automatically set as the fulfillment of the chained Promise (from the first point).
Let's first illustrate what that means, and then we'll derive how that helps us create async sequences of flow control. Consider the following:

var p = Promise.resolve( 21 );

var p2 = p.then( function(v){
	console.log( v );	// 21

	// fulfill `p2` with value `42`
	return v * 2;
} );

// chain off `p2`
p2.then( function(v){
	console.log( v );	// 42
} );

By returning v * 2 (i.e., 42), we fulfill the p2 promise that the first then(..) call created and returned. When p2's then(..) call runs, it's receiving the fulfillment from the return v * 2 statement. Of course, p2.then(..) creates yet another promise, which we could have stored in a p3 variable.

But it's a little annoying to have to create an intermediate variable p2 (or p3, etc.). Thankfully, we can easily just chain these together:

var p = Promise.resolve( 21 );

p
.then( function(v){
	console.log( v );	// 21

	// fulfill the chained promise with value `42`
	return v * 2;
} )
// here's the chained promise
.then( function(v){
	console.log( v );	// 42
} );

So now the first then(..) is the first step in an async sequence, and the second then(..) is the second step. This could keep going for as long as you needed it to extend. Just keep chaining off a previous then(..) with each automatically created Promise.

But there's something missing here. What if we want step 2 to wait for step 1 to do something asynchronous? We're using an immediate return statement, which immediately fulfills the chained promise.

The key to making a Promise sequence truly async capable at every step is to recall how Promise.resolve(..) operates when what you pass to it is a Promise or thenable instead of a final value. Promise.resolve(..) directly returns a received genuine Promise, or it unwraps the value of a received thenable -- and keeps going recursively while it keeps unwrapping thenables.

The same sort of unwrapping happens if you return a thenable or Promise from the fulfillment (or rejection) handler. Consider:

var p = Promise.resolve( 21 );

p.then( function(v){
	console.log( v );	// 21

	// create a promise and return it
	return new Promise( function(resolve,reject){
		// fulfill with value `42`
		resolve( v * 2 );
	} );
} )
.then( function(v){
	console.log( v );	// 42
} );

Even though we wrapped 42 up in a promise that we returned, it still got unwrapped and ended up as the resolution of the chained promise, such that the second then(..) still received 42. If we introduce asynchrony to that wrapping promise, everything still nicely works the same

var p = Promise.resolve( 21 );

p.then( function(v){
	console.log( v );	// 21

	// create a promise to return
	return new Promise( function(resolve,reject){
		// introduce asynchrony!
		setTimeout( function(){
			// fulfill with value `42`
			resolve( v * 2 );
		}, 100 );
	} );
} )
.then( function(v){
	// runs after the 100ms delay in the previous step
	console.log( v );	// 42
} );

That's incredibly powerful! Now we can construct a sequence of however many async steps we want, and each step can delay the next step (or not!), as necessary.

Of course, the value passing from step to step in these examples is optional. If you don't return an explicit value, an implicit undefined is assumed, and the promises still chain together the same way. Each Promise resolution is thus just a signal to proceed to the next step.

To further the chain illustration, let's generalize a delay-Promise creation (without resolution messages) into a utility we can reuse for multiple steps:

function delay(time) {
	return new Promise( function(resolve,reject){
		setTimeout( resolve, time );
	} );
}

delay( 100 ) // step 1
.then( function STEP2(){
	console.log( "step 2 (after 100ms)" );
	return delay( 200 );
} )
.then( function STEP3(){
	console.log( "step 3 (after another 200ms)" );
} )
.then( function STEP4(){
	console.log( "step 4 (next Job)" );
	return delay( 50 );
} )
.then( function STEP5(){
	console.log( "step 5 (after another 50ms)" );
} )
...

Calling delay(200) creates a promise that will fulfill in 200ms, and then we return that from the first then(..) fulfillment callback, which causes the second then(..)'s promise to wait on that 200ms promise.

Note: As described, technically there are two promises in that interchange: the 200ms-delay promise and the chained promise that the second then(..) chains from. But you may find it easier to mentally combine these two promises together, because the Promise mechanism automatically merges their states for you. In that respect, you could think of return delay(200) as creating a promise that replaces the earlier-returned chained promise.

To be honest, though, sequences of delays with no message passing isn't a terribly useful example of Promise flow control. Let's look at a scenario that's a little more practical

// assume an `ajax( {url}, {callback} )` utility

// Promise-aware ajax
function request(url) {
	return new Promise( function(resolve,reject){
		// the `ajax(..)` callback should be our
		// promise's `resolve(..)` function
		ajax( url, resolve );
	} );
}

request( "http://some.url.1/" )
.then( function(response1){
	return request( "http://some.url.2/?v=" + response1 );
} )
.then( function(response2){
	console.log( response2 );
} );

Note: Developers commonly encounter situations in which they want to do Promise-aware async flow control with utilities that are not themselves Promise-enabled (like ajax(..) here, which expects a callback). Although the native ES6 Promise mechanism doesn't automatically solve this pattern for us, practically all Promise libraries do. They usually call this process "lifting" or "promisifying" or some variation thereof. We'll come back to this technique later.

Using the Promise-returning request(..), we create the first step in our chain implicitly by calling it with the first URL, and chain off that returned promise with the first then(..).

Once response1 comes back, we use that value to construct a second URL, and make a second request(..) call. That second request(..) promise is returned so that the third step in our async flow control waits for that Ajax call to complete. Finally, we print response2 once it returns.

The Promise chain we construct is not only a flow control that expresses a multistep async sequence, but it also acts as a message channel to propagate messages from step to step.

What if something went wrong in one of the steps of the Promise chain? An error/exception is on a per-Promise basis, which means it's possible to catch such an error at any point in the chain, and that catching acts to sort of "reset" the chain back to normal operation at that point:

// step 1:
request( "http://some.url.1/" )

// step 2:
.then( function(response1){
	foo.bar(); // undefined, error!

	// never gets here
	return request( "http://some.url.2/?v=" + response1 );
} )

// step 3:
.then(
	function fulfilled(response2){
		// never gets here
	},
	// rejection handler to catch the error
	function rejected(err){
		console.log( err );	// `TypeError` from `foo.bar()` error
		return 42;
	}
)

// step 4:
.then( function(msg){
	console.log( msg );		// 42
} );

When the error occurs in step 2, the rejection handler in step 3 catches it. The return value (42 in this snippet), if any, from that rejection handler fulfills the promise for the next step (4), such that the chain is now back in a fulfillment state.

Note: As we discussed earlier, when returning a promise from a fulfillment handler, it's unwrapped and can delay the next step. That's also true for returning promises from rejection handlers, such that if the return 42 in step 3 instead returned a promise, that promise could delay step 4. A thrown exception inside either the fulfillment or rejection handler of a then(..) call causes the next (chained) promise to be immediately rejected with that exception.

If you call then(..) on a promise, and you only pass a fulfillment handler to it, an assumed rejection handler is substituted:

var p = new Promise( function(resolve,reject){
	reject( "Oops" );
} );

var p2 = p.then(
	function fulfilled(){
		// never gets here
	}
	// assumed rejection handler, if omitted or
	// any other non-function value passed
	// function(err) {
	//     throw err;
	// }
);

As you can see, the assumed rejection handler simply rethrows the error, which ends up forcing p2 (the chained promise) to reject with the same error reason. In essence, this allows the error to continue propagating along a Promise chain until an explicitly defined rejection handler is encountered.

Note: We'll cover more details of error handling with Promises a little later, because there are other nuanced details to be concerned about.

If a proper valid function is not passed as the fulfillment handler parameter to then(..), there's also a default handler substituted:


var p = Promise.resolve( 42 );

p.then(
	// assumed fulfillment handler, if omitted or
	// any other non-function value passed
	// function(v) {
	//     return v;
	// }
	null,
	function rejected(err){
		// never gets here
	}
);


As you can see, the default fulfillment handler simply passes whatever value it receives along to the next step (Promise).

Note: The then(null,function(err){ .. }) pattern -- only handling rejections (if any) but letting fulfillments pass through -- has a shortcut in the API: catch(function(err){ .. }). We'll cover catch(..) more fully in the next section.

Let's review briefly the intrinsic behaviors of Promises that enable chaining flow control:

A then(..) call against one Promise automatically produces a new Promise to return from the call.
Inside the fulfillment/rejection handlers, if you return a value or an exception is thrown, the new returned (chainable) Promise is resolved accordingly.
If the fulfillment or rejection handler returns a Promise, it is unwrapped, so that whatever its resolution is will become the resolution of the chained Promise returned from the current then(..).

While chaining flow control is helpful, it's probably most accurate to think of it as a side benefit of how Promises compose (combine) together, rather than the main intent. As we've discussed in detail several times already, Promises normalize asynchrony and encapsulate time-dependent value state, and that is what lets us chain them together in this useful way.

Certainly, the sequential expressiveness of the chain (this-then-this-then-this...) is a big improvement over the tangled mess of callbacks as we identified in Chapter 2. But there's still a fair amount of boilerplate (then(..) and function(){ .. }) to wade through. In the next chapter, we'll see a significantly nicer pattern for sequential flow control expressivity, with generators.

erminology: Resolve, Fulfill, and Reject
There's some slight confusion around the terms "resolve," "fulfill," and "reject" that we need to clear up, before you get too much deeper into learning about Promises. Let's first consider the Promise(..) constructor:

var p = new Promise( function(X,Y){
	// X() for fulfillment
	// Y() for rejection
} );

As you can see, two callbacks (here labeled X and Y) are provided. The first is usually used to mark the Promise as fulfilled, and the second always marks the Promise as rejected. But what's the "usually" about, and what does that imply about accurately naming those parameters?

Ultimately, it's just your user code and the identifier names aren't interpreted by the engine to mean anything, so it doesn't technically matter; foo(..) and bar(..) are equally functional. But the words you use can affect not only how you are thinking about the code, but how other developers on your team will think about it. Thinking wrongly about carefully orchestrated async code is almost surely going to be worse than the spaghetti-callback alternatives.

So it actually does kind of matter what you call them.

The second parameter is easy to decide. Almost all literature uses reject(..) as its name, and because that's exactly (and only!) what it does, that's a very good choice for the name. I'd strongly recommend you always use reject(..).

But there's a little more ambiguity around the first parameter, which in Promise literature is often labeled resolve(..). That word is obviously related to "resolution," which is what's used across the literature (including this book) to describe setting a final value/state to a Promise. We've already used "resolve the Promise" several times to mean either fulfilling or rejecting the Promise.

But if this parameter seems to be used to specifically fulfill the Promise, why shouldn't we call it fulfill(..) instead of resolve(..) to be more accurate? To answer that question, let's also take a look at two of the Promise API methods:

var fulfilledPr = Promise.resolve( 42 );

var rejectedPr = Promise.reject( "Oops" );

Promise.resolve(..) creates a Promise that's resolved to the value given to it. In this example, 42 is a normal, non-Promise, non-thenable value, so the fulfilled promise fulfilledPr is created for the value 42. Promise.reject("Oops") creates the rejected promise rejectedPr for the reason "Oops".

Let's now illustrate why the word "resolve" (such as in Promise.resolve(..)) is unambiguous and indeed more accurate, if used explicitly in a context that could result in either fulfillment or rejection:

var rejectedTh = {
	then: function(resolved,rejected) {
		rejected( "Oops" );
	}
};

var rejectedPr = Promise.resolve( rejectedTh );

As we discussed earlier in this chapter, Promise.resolve(..) will return a received genuine Promise directly, or unwrap a received thenable. If that thenable unwrapping reveals a rejected state, the Promise returned from Promise.resolve(..) is in fact in that same rejected state.

So Promise.resolve(..) is a good, accurate name for the API method, because it can actually result in either fulfillment or rejection.

The first callback parameter of the Promise(..) constructor will unwrap either a thenable (identically to Promise.resolve(..)) or a genuine Promise:

var rejectedPr = new Promise( function(resolve,reject){
	// resolve this promise with a rejected promise
	resolve( Promise.reject( "Oops" ) );
} );

rejectedPr.then(
	function fulfilled(){
		// never gets here
	},
	function rejected(err){
		console.log( err );	// "Oops"
	}
);

It should be clear now that resolve(..) is the appropriate name for the first callback parameter of the Promise(..) constructor.

Warning: The previously mentioned reject(..) does not do the unwrapping that resolve(..) does. If you pass a Promise/thenable value to reject(..), that untouched value will be set as the rejection reason. A subsequent rejection handler would receive the actual Promise/thenable you passed to reject(..), not its underlying immediate value.

But now let's turn our attention to the callbacks provided to then(..). What should they be called (both in literature and in code)? I would suggest fulfilled(..) and rejected(..):

function fulfilled(msg) {
	console.log( msg );
}

function rejected(err) {
	console.error( err );
}

p.then(
	fulfilled,
	rejected
);
\\Error Handling
We've already seen several examples of how Promise rejection -- either intentional through calling reject(..) or accidental through JS exceptions -- allows saner error handling in asynchronous programming. Let's circle back though and be explicit about some of the details that we glossed over.

The most natural form of error handling for most developers is the synchronous try..catch construct. Unfortunately, it's synchronous-only, so it fails to help in async code patterns:

function foo() {
	setTimeout( function(){
		baz.bar();
	}, 100 );
}

try {
	foo();
	// later throws global error from `baz.bar()`
}
catch (err) {
	// never gets here
}
try..catch would certainly be nice to have, but it doesn't work across async operations. That is, unless there's some additional environmental support, which we'll come back to with generators in Chapter 4.

In callbacks, some standards have emerged for patterned error handling, most notably the "error-first callback" style:

function foo(cb) {
	setTimeout( function(){
		try {
			var x = baz.bar();
			cb( null, x ); // success!
		}
		catch (err) {
			cb( err );
		}
	}, 100 );
}

foo( function(err,val){
	if (err) {
		console.error( err ); // bummer :(
	}
	else {
		console.log( val );
	}
} );

Note: The try..catch here works only from the perspective that the baz.bar() call will either succeed or fail immediately, synchronously. If baz.bar() was itself its own async completing function, any async errors inside it would not be catchable.

The callback we pass to foo(..) expects to receive a signal of an error by the reserved first parameter err. If present, error is assumed. If not, success is assumed.

This sort of error handling is technically async capable, but it doesn't compose well at all. Multiple levels of error-first callbacks woven together with these ubiquitous if statement checks inevitably will lead you to the perils of callback hell (see Chapter 2).

So we come back to error handling in Promises, with the rejection handler passed to then(..). Promises don't use the popular "error-first callback" design style, but instead use "split callbacks" style; there's one callback for fulfillment and one for rejection:

var p = Promise.reject( "Oops" );

p.then(
	function fulfilled(){
		// never gets here
	},
	function rejected(err){
		console.log( err ); // "Oops"
	}
);

var p = Promise.resolve( 42 );

p.then(
	function fulfilled(msg){
		// numbers don't have string functions,
		// so will throw an error
		console.log( msg.toLowerCase() );
	},
	function rejected(err){
		// never gets here
	}
);

If the msg.toLowerCase() legitimately throws an error (it does!), why doesn't our error handler get notified? As we explained earlier, it's because that error handler is for the p promise, which has already been fulfilled with value 42. The p promise is immutable, so the only promise that can be notified of the error is the one returned from p.then(..), which in this case we don't capture.

That should paint a clear picture of why error handling with Promises is error-prone (pun intended). It's far too easy to have errors swallowed, as this is very rarely what you'd intend.

Warning: If you use the Promise API in an invalid way and an error occurs that prevents proper Promise construction, the result will be an immediately thrown exception, not a rejected Promise. Some examples of incorrect usage that fail Promise construction: new Promise(null), Promise.all(), Promise.race(42), and so on. You can't get a rejected Promise if you don't use the Promise API validly enough to actually construct a Promise in the first place!

Jeff Atwood noted years ago: programming languages are often set up in such a way that by default, developers fall into the "pit of despair" (http://blog.codinghorror.com/falling-into-the-pit-of-success/) -- where accidents are punished -- and that you have to try harder to get it right. He implored us to instead create a "pit of success," where by default you fall into expected (successful) action, and thus would have to try hard to fail.

Promise error handling is unquestionably "pit of despair" design. By default, it assumes that you want any error to be swallowed by the Promise state, and if you forget to observe that state, the error silently languishes/dies in obscurity -- usually despair.

To avoid losing an error to the silence of a forgotten/discarded Promise, some developers have claimed that a "best practice" for Promise chains is to always end your chain with a final catch(..), like:

var p = Promise.resolve( 42 );

p.then(
	function fulfilled(msg){
		// numbers don't have string functions,
		// so will throw an error
		console.log( msg.toLowerCase() );
	}
)
.catch( handleErrors );

Because we didn't pass a rejection handler to the then(..), the default handler was substituted, which simply propagates the error to the next promise in the chain. As such, both errors that come into p, and errors that come after p in its resolution (like the msg.toLowerCase() one) will filter down to the final handleErrors(..).

Problem solved, right? Not so fast!

What happens if handleErrors(..) itself also has an error in it? Who catches that? There's still yet another unattended promise: the one catch(..) returns, which we don't capture and don't register a rejection handler for.

You can't just stick another catch(..) on the end of that chain, because it too could fail. The last step in any Promise chain, whatever it is, always has the possibility, even decreasingly so, of dangling with an uncaught error stuck inside an unobserved Promise.

Sound like an impossible conundrum yet?

Uncaught Handling
It's not exactly an easy problem to solve completely. There are other ways to approach it which many would say are better.

Some Promise libraries have added methods for registering something like a "global unhandled rejection" handler, which would be called instead of a globally thrown error. But their solution for how to identify an error as "uncaught" is to have an arbitrary-length timer, say 3 seconds, running from time of rejection. If a Promise is rejected but no error handler is registered before the timer fires, then it's assumed that you won't ever be registering a handler, so it's "uncaught."

In practice, this has worked well for many libraries, as most usage patterns don't typically call for significant delay between Promise rejection and observation of that rejection. But this pattern is troublesome because 3 seconds is so arbitrary (even if empirical), and also because there are indeed some cases where you want a Promise to hold on to its rejectedness for some indefinite period of time, and you don't really want to have your "uncaught" handler called for all those false positives (not-yet-handled "uncaught errors").

Another more common suggestion is that Promises should have a done(..) added to them, which essentially marks the Promise chain as "done." done(..) doesn't create and return a Promise, so the callbacks passed to done(..) are obviously not wired up to report problems to a chained Promise that doesn't exist.

So what happens instead? It's treated as you might usually expect in uncaught error conditions: any exception inside a done(..) rejection handler would be thrown as a global uncaught error (in the developer console, basically):

var p = Promise.resolve( 42 );

p.then(
	function fulfilled(msg){
		// numbers don't have string functions,
		// so will throw an error
		console.log( msg.toLowerCase() );
	}
)
.done( null, handleErrors );

// if `handleErrors(..)` caused its own exception, it would
// be thrown globally here