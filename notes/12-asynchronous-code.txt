Asynchronous code
Introduction:
Since javascriptg is the language of the web, thre are some functions that by necessity are goingt o take a decent
amount of itme to cpmlete, sucha s fetching data from a server to display on your site. For this reason, jagvascdript includes
support for asynchrounous functions, or to put it another way, functions that can happen in the background while the rest of your code executes.

Lesson OVerveiw:
This section contains a general overview of topics you will learn in this lesson. Explain what a callback is
explain what a promise is
explain the circumsttance which promises are better than clalbacks
explain the .then() functions

Callbacks:
In the recent past, the way that these were most commonly handled were with callbacks, and even now they are stil use
quite a lot in certain circumstances.
A callback fucniton is a function passed into another function as an argument, which is then invoked inside the outer function to complete some kind of routine or aciton.

Callbacks are functions that get passed into other functions.

For example:
    myDiv.addEventListern("click", function()){
    DO SOMETHINGGG
    }

Here, the function addEventListern() takes a callback ("the do something" funciton) and then aclls it when myDiv gest clicked>
YOu will likely recognize htis pattern as something that hpapens all the time in javascript code.
Unfortuantely, though they are useful in situations like the above example,Â using callbacks can get out of hand, especially when you need to chain several of htem together in a specific
order. the rest of htis lesson discusses pattersn and functions that will help keep you out of callback hell.

Promises:
There are multiple ways that you can handle asynchronous code in JavaScrfipt, and they all have their use cases.
Promises are one such mechanism, and they're on you will see somewhat often when using other libraries or frameworks. Knowing 
what thye are and how to use them is quite useful.

Essentially, a promise is an object that might produce a value at some point in the future.

Lets say getData()is a function that fetches some data from a server and retunrs it as on object that we can use in our code:

const getData = function() {
    //go fetch data from some APi
    //clean it up a bit return it as an object
    return data.
}
The issue with this example is that it takes some time to fetche the data, but unless we tell our code that, it assumes that everything in the funciton happens essentially instantly.

So if we try this:
const myData = getData()
const pieceOfData = myData["whatever"]

WE're going to run into trouble because when we try to extract pieceOfData out of the returned data,
the funciton getData() will mostlikely still be fetchingh, so myData will not be the expected data,
but will be undefined. Sad.

We need some way to solve this problem, and tell our code to wait until the data is done fetching to continue. Promises solve this issue. 



const myData = getData() //if this is refactored to return a promise...


myData.then(function(data) [//.,then() tell is to wait until the promise is resolved
    const pieceOfData = data["whatever]//and THEN run the function inside.
])



Article:https://davidwalsh.name/promises

While synchronous code is easeir to follow and debug, async is generally ebtter for performance and flexiibility.
Why "hold up the show" when you can trigger numerous requests at once and then handle them when each si ready?
Promsies are becoming a big part of the javascript world, with many new APIS being implemented witht hep rmose philosophy.


Promises in the wild:
The XMLHttpRequest API is async but does NOT use the promises API. TGhere are a few native apis that now use promises however.
    Battery API
    fetch API
    ServiceWorker API

Promises will only become more prevalent so its important that allf ront-end developers get used to them.
Its also worht noting that node.js is another platform for promises. Obviously as promise is a core language features.

Basic Promise Usage:
The new Promise() constructor should only be used fo rlegacy async tasks, like the usage of setTimeout or XMLHttpRequest. 
AA new promsie is created with the new keyword and the promise provides resolvea dn reject funcitons to the provided callback:

var p = new Promise(function(resolve, reject) {
	
	// Do an async task async task and then...

	if(/* good condition */) {
		resolve('Success!');
	}
	else {
		reject('Failure!');
	}
});

p.then(function(result) { 
	/* do something with the result */
}).catch(function() {
	/* error : */
}).finally(function() {
   /* executes regardless or success for failure */ 
});



Sometimes you dont NEED to complete an async takss within the promise.
returning a promise will be best so taht you can always count on ap romise coming out of a given fucniton.
IN that case, you acn simply call promise.reolve() of promise.reject() without using the new keyword


Callbacks: https://github.com/getify/You-Dont-Know-JS/blob/1st-ed/async%20%26%20performance/ch2.md

IN chapter 1, we explored the terminology adn concepts around asynchronous programming in javascript.
Our focus is onudnerstandint he single-threaded (one at a time) event lop queue that
drives all events. WE also explored vairous ways that concurrency pattersn explains the relationshipos
between any simultaneously running chains of events, or processes.

All oru examples in chapter 1 use the funciton as the individual, indivisible unit of operations, whereby inside
the funciton, statements run in predictrable order ( above the ocmpiler level) but at the
funciton ordering level, events (aka async funciton invocations) can happen in a variety or ordres.

In all these cases, the funciton is a cting as a "callback" because it serves as the target for the event loop
to "call back into" the program, whenever that item in theq eueu is processed.

As you no doubt have observed, callbacks are by far the most common way that asynchronoy in JavaScrfipt
prorams is expressed and managed. Inded, the callback is the most fundamental async pattenr in the language.


Countless JS programs, even very sophisticated and compelx ones, have been written upon no other async foundation than the callback.
(with of course the concurrency interaction patterns we explored in chapte r1) The callback fucniton is the async work horse for javascript, and it does its job respectabl.

Except... Callbacks are not without their shortcomings. Many developers are excited by the PROMSE of better async patterns. But its impossible to effectively use any abstraciton if you don't
understand what its abstracting, and whyl.


Continuations:

// A
ajax( "..", function(..){
	// C
} );
// B


// A and // B represent the first half of the program (aka the now), and // C marks the second half of the program (aka the later). The first half executes right away, and then there's a "pause" of indeterminate length. At some future moment, if the Ajax call completes, then the program will pick up where it left off, and continue with the second half.

In other words, the callback function wraps or encapsulates the continuation of the program.

Let's make the code even simpler:

// A
setTimeout( function(){
	// C
}, 1000 );
// B


Stop for a moment and ask yourself how you'd descrfibe the wayt hat program behaves. 
try it out loud. Its a good exercise that will help my next points make sense.


Most readres just now probably thought or said something to the effect of: "Do A, then set up a setTimeout
to wait1,000 milliseconds, then once that fires, do c. How close was your rendition?

You might have cauvht yourself and self-edited to: "do A, setup the timeout for 1,000 milliseconds, then
do b, then after the timeout fires, do C. Thats more accurate thatn the first version


Even though the second version is more accurate, both versions are deficient in explaining this code
in a way that matches our brains to the code and the code to the JS engine. The disconnect is both subtle and monumental.
and is at the very herat of understanding the shortcomings of callbacks as async expression and management.

As soon as we introduce a single fcontiuation. In the ofrm of a callback function, we have a allowed a divergence
to form between how our brains work and the way th ecode will operate. Any time these two diverge (and this is by far no the only place that happens,)
we run into the inevitable fact that our code becomes harder to udnerstand, reason about, debug, and maintain.


Sequential Brain:
I'm pretty sure most of your readeres have heard someone say "i'm a multitasker" The effects of trying to act
as  a multitasker range from humorous to mundane to downright dangerous.

But are we multitaskers? Can we really do two conscious, intentional actions at once and think/reason about both of htem at 
exactly the samem moment? Does our highest level of brain funcitonality have parallel multithreading going on?
probably not.



Thats just not really how our brains appear to be set up. We're much more single taskers than many of us would like to admit.
We can really only think about one thing at anygiven instant.

I'm not talking about all our invaluntary, subconciuos, automatic brain functions, suchas heart beating, breathing, and eyelid blinking.
Thes are all vital tasks to our sustained life, but we don't intentionally allcoate any rbain power to them.
Thankfully, while we obsses about checking social network feeds for the 15th time in three minutes, our brain carries on in the background (Threads!) 
withall those important tasks.

WE're instead talking about whatever task is at the forefront of our minds at the moment. For me its writing the text in this book right now.
Am I doing any other higher level brain function at exactly this same moement? Nope, not really. I get disttracted quickly and easily -- a few
dozen times in thes last couple of paragraphs!

WHen we fake multitasking, such as trying to type something at the same ttime we're talking to a friend or family emmeber on the phone,
what we're actually most likely doing is acting as fast context switchers. In other words, we switch back and forth bewtween two or more tasks in rapid succession, 
simultaneously progressing on each task in tiny, fast little cunks. We do it so fast that to the outside world it appears as if we're doing those things in parallel.

DSoes that sound suspiciously like async evented concurrency to you?
If not, go back and read chapter 1 again!

In fact, one way of simplifying, the massively complex world of neurology into somethign I can remotely hope to discuss here is that our brains work kind like the event loop queue.

If you think about every single letter or word I type as a single async event, in jsut this sentence alone there are severeal dozen opportunities for my brain to be interrupted by some tother event, 
such as from m y sense, or even just my random thoughts.

I don't get interrupted and pulled ot another "process" at every oppporutnity that I could be.
But it happens often enough that I feel my own brain is nearly constanlty switching to variou sdifferent contexts and thats an awful lot like howt he js engine would probably fel.


DOING VS PLANNING:
Ok so our brains can thought of as operating in single threaded event loop queue like ways, as can the JS engine.
But we need to be more nuanced than that in our analysis. There's a big, observable difference between how we plan various tasks,
and how our brains actually operate those tasks.

Again, back ot the wriitng of htis text as my metahpor,. My rough mental outline plan here is to keep wriitng and writing,
going sequentially through a set of points I have ordered in my thoguhts. I don't plan to have any interruptions or nonlinear activity in this wriitng.
But yeet, my brain is nevertheless swithcing around all the time.

Even though at an operational level our brains are async event3ed, weseem to plaln out tasks in a sequqneial synchronous wayl. "i nee to go to the store then buy some ilk, then drop off my dry cleaning".

You'll noce that this higher level thinking doesn't seem very async event3ed in its formulation.
In fact, its kidn of rare for us to delibterately think solely in terms of events. Intead, we lan things out carefully, sequentially,
and then we assume to an extrent a sort of temporal blocking that forces b to wai t on A and c to wa it on B.

When a developer writews code, they are planning out a set of actions to occur. If htey're any good at being a developer, they're carefully planning it out. I need to set z to the value ofx, then x to the value of y and so forth..
z = x;
x = 7;
y = x;

These three assignment statements are synchronous, so x=y waits for x=x to finish, and y = z in tyrn ways for x=7 to finish. 
Another way of saying it is that these three statements are temporarily bound to execute in a certain order, one right after the other. Thankfully, we don't need to be bothered with any async evented details here.

So if synchronous brain planning maps well to synchronous code statement,s how well do our brains at planning out asynchronous code?
It turnms out how we express asynchronoy in our code doesn't map very well at all to that synchronous brain planning behavior.

We think in step by step terms, but the tools (callbacks) available to us in code aren ot expressed in a step by step fashion once we move from synchronous to asynchronous.

And THAT is why its so hard to accurately author and reason about async JS code with callbacks:
because thats now how our pbrain planing works.
Note: The only thing worse than not knowing why some code breaks is not knowing why it worked in the first place! It's the classic "house of cards" mentality: "it works, but not sure why, so nobody touch it!" You may have heard, "Hell is other people" (Sartre), and the programmer meme twist, "Hell is other people's code." I believe truly: "Hell is not understanding my own code." And callbacks are one main culprit.



Nested/Chained callbacks:
listen( "click", function handler(evt){
	setTimeout( function request(){
		ajax( "http://some.url.1", function response(text){
			if (text == "hello") {
				handler();
			}
			else if (text == "world") {
				request();
			}
		} );
	}, 500) ;
} );

Threres a good chance code like that is recognizable to you. WE've got a chian of three funcitons ensted together, each one representing a step in an asynchronous series.


This kidn of code is often called "callback hell" and sometimes also referred to as the pyramid of dooml.

But callback hell actually has almost nothing to do with the nesting/inentatin. Its a far deeper problem than that. We'll see how and why as we continue through the rest of this chapter.

FIrst we're waiting for the "click" event, then we're waiting for hte timer to fire, then we're waiting for hte ajax repsponse to come back ,and which point we might do it alla gian.


listen( "click", handler );

function handler() {
	setTimeout( request, 500 );
}

function request(){
	ajax( "http://some.url.1", response );
}

function response(text){
	if (text == "hello") {
		handler();
	}
	else if (text == "world") {
		request();
	}
}

This formulation of the code is not hardly as recognizxable as hagving the nesting/indentation woes of its previous form,
and yet its every bit as suceptible to"callback hell". WHy?

As we go linearly (sequentially reason) about this code, we have to skip from one function to hte next,
to the next, and bounce all around the code base to see the qsequence flow.
As remember, this is simplified code in sort of best-case fashion, We all know that real async JS p[rogram code bases are
often fantastically more jmbled, which makes such reasoning order of magnitude more difficult]


Another thing to noice: to get steps 2,3, and 4 linked together so they happen in succession, the noly affordance callbacks alone
gives us to hardcore step 2 into step 1, step 3 into step 22, step 4 into step 3 asnd so on. The hardcoding isn't necessarily a bad thing, if it
really is a fixed condition that step 2 should always lead to step 3.

But the hardcoding defnitely makes the code a bit more brittle, as it doesn't account for angything going wrong
that might cause a edeviation int he progression of steps. For exapmle, if step 2 fails, step 3 never gets reached, nord oes step 2 retry, or move ot an alternate error handling flow, and so on.


All of these issues are things you CAN manually hardcode into each step, but that code is often very repetetive and not reuseable in other steps or in other async flows in your program.

Even though our brains might plan out a series of tasks in a sequential type of way (this, then this, then this) the evented nature of our brain operation makes recovery retry forking of flow control almsot efortless.
If you're out r unning errands, and you realize you left a shoppin glist at home, it doesn't end the day b ecause you didn't plan that ahead of itme. your brain routes aroudn this hiccup easily: you got home, get a list, then head right back out to the store.


But the brittle nature of manually hardocded callbacks (even with haredcoded error handling) is often far less graceful. Once you end up speciiying (aka preplaning) all the various eventulaities/paths,
the code becomes so convoluted that it s hard to ever maintain or update it.

THAT is what "callback hell" is all about! The nesting/indentation are basically a side show, a red herring.

And as if all thats not enough, we haven't even touched what happens hen two or more chains of thse callback contiuatinos are happening SIMULATANEOUSLY, or whent eh third step branches out in "parallel" callbacks
with gates or latches/



Trust ISSUES:
The mismatch between sequential brain planning and callback driven async js code is the only part o the problem wit h callbacks. Theres somethign muchd eeper to be concerned about.

// A
ajax( "..", function(..){
	// C
} );
// B

// A and // B happeng NOW, under the direct control of the main JS program. but //c gets deferred to happen later, and udner the contorl of anothe rparty -- in this case, the ajax(..) funciton. In a basic sense,
that sort of hand-off of o control doesn't regularly cause lots of problems for programs.


But don't be fooled by its infrequency that this control switch isn't a bitg deal. in fact, its one of the worst (and yet most subtle) problems
about callbacjk-driven design. It reolves around the idea that sometimes 
the party that hnaldes your callback contuation is not a function that you wrote, or that you direclty control.
Many times, its a utility provided by some third party.

WE call this "inversion of control", when you take part o fyour program and give control of its executiont o another third party. There's an unspoken
"contract" that e4xists between your code and the third party utility -- a set of htings youe xpect to be maintained.


Tale of five callbacks:
It might noe bt terribly obvious why this is such a big deal. Let me construct an exaggerated scenario to illustrate the hazards of trust at play.

IMagine yoiu're a developer taske with building out an ecommerce checkout system for a site that sells expesnive TV's. You alreaedy have all the various pages of the checkout stystem builto ut just fine.
 On the last page, when the user clicks "confirm" to buy the TV, you need to call a third-party function so that the sale can be tracked.

 You noticve that htye've provided what looks like an asynct racking utility, probably for the sak eof performance best practices, which means you need to pass in a callback funciton. in this contiunation that you pass in,
 you will have the final code that charges the customer's cr3edit card and dislays the thank yo upage.

 analytics.trackPurchase( purchaseData, function(){
	chargeCreditCard();
	displayThankyouPage();
} );

Easy enough, right? You write the code, test it, eerything works, and you deploy to production> everyone's happy.

Six months go by anad no isues. You've almost forgotten you even wrote that code. Once morning you're at a coffee shop before work, casually enjoyuing your latte, when you get pacnkicked clal form your boss
insisting you drop the coffe and rush into work right away.

When you arrive, you'll findo ut that high profile customer has his credit card charrged five times for the same tv, and he's understandbly upset. CUstomer service has already issued
an apology and processed a refund. But your boiss demsnds to know how this could possibly have happened. "don't we have tests for stuff like this?"

YOu don't even rememebr the code you wrote. But you dig back in and start trying to find out what could ahve gone awry.

AFter digging through some logs, you come to the conclusion that the only explanation is that the analytics utilty somehow, for some reason, called your callback five times tinstead of once. Nohting in their documentation mentions anything baout this.

Frustratec,you ocontat customer support, who of course is as astonished as you are. They agree to escalate it to their developers and promose to get back to you.
The next day, you recive aq lenghty email explaining what they found, which you promptly forward to your boss.

Apparently, the developers at the analytics companyh had been working on some experimetnba code that, uner ertain conditions, would retry to the provided callback once per second, for five seconds, before fialing with a timeout.
They had never inteded to push that into production, but somehow they did, and they're totally embarassed and apologetic. They go into plenty of detail about how they've
identified the breakdown adn what they'll do to ensure it enver happens again.yadda, yadda.
Whats next?

YOu talk it over with your boss, but hes not feeling particularly comfortable witht eh state of things. he insi9sts, and you reluctantly agree, taht you fan't trust tthem anymore
and that you'll need to figure out how to protect hte checkout code from such a vulnerability again.


Example code for tracking checkouts.
var tracked = false;

analytics.trackPurchase( purchaseData, function(){
	if (!tracked) {
		tracked = true;
		chargeCreditCard();
		displayThankyouPage();
	}
} );

But one of your WA engineers asks "What happen sif they never call the callback? Oops. Neitehr of you had thought about that.

You beging to chase down the rabbit hole, and think of all the possible things that could go wrong weith them calling your callback.
Here's roughly the list you come up with of ways the analytics utility could misbehave:

	Call the callback too early (before its been tracked)
	Call the callback too late (or never)
	call the callback too few or too many times (like the problem you encountered!)
	Fail to pass along any necessary environment/parameters to your callback.
	Swallow any errors/exceptions that may happen.

That hsould feel like a troubling list, because it is. You're probably slowly starting to realize that you're going to have to invent an awful lot of ad hoc logic in each and every single callback
thats passed to a utility you're not positive you can trust.
Now yo realize a bit more completely just how hellish "callback hell is"


Not just others code:
Some of you mayu be skeptical at this point whether this is as big a deal as i'm making it out to be. Perhaps you don't interact wiht truly third-party utilities much if at all.
Herpahs you use version APIS or self-host such lirbaries, sot aht tis behavior can't be changed out from underneath you.

So contemplate this: can you even REALLY trust utilities that you do theoretically control in your own code base?

Think of it this way: most of us agree that at least to some extent we should bulid our own internal functions ith some defensive checks ont he input parameters,  to reduce/prevent uenxepcted issues.

function addNumbers(x,y) {
	// + is overloaded with coercion to also be
	// string concatenation, so this operation
	// isn't strictly safe depending on what's
	// passed in.
	return x + y;
}

addNumbers( 21, 21 );	// 42
addNumbers( 21, "21" );	// "2121"

Defensive version of code:
function addNumbers(x,y) {
	// ensure numerical input
	if (typeof x != "number" || typeof y != "number") {
		throw Error( "Bad parameters" );
	}

	// if we get here, + will safely do numeric addition
	return x + y;
}

addNumbers( 21, 21 );	// 42
addNumbers( 21, "21" );	// Error: "Bad parameters"




However you go about it, these sorts of checks/normalizations are failry common on fucntion inputs, evne with code we theoretically entirely trust. IN a crude sort of way, its like the programming equivalent of the geopolitical principle fo "trust but verify"

So doesn't it stadn to treason that we should do the same thing about the copmosition of async funciton callbacks, not just with truly external code but even with code we know is generall udner our own control? OF COURSE WE SHOULD.

But callbacks don't really offer anythign to assist us. We have to construct all that machinery ourselves, and it often ends up being a lot of boilerplate/overhead that we repeat for every single async callback.
The most troublesome problem with callbacks is inversion of control leading to a complete breakdown along those trust lines. If you ahve code tha tuses callbacks,
especially but not exclusively with third-party utilties, and you're not already aplying some sort of mitigation logic for all thes e inversion of contrrol trust issues, your code AHS bugs in it right now even thought ehy nay not have beitten you yet.
Latent bugs ar estill bugs,. Hell indeed.


Trying to save calllbacks:
There are several variations of callback design that have attempted toa ddress some (not all!) of the trust issues we've just looked at.
Its a valiant, but doomed, effort to save the callback pattern from imploding on itself.

function success(data) {
	console.log( data );
}

function failure(err) {
	console.error( err );
}

ajax( "http://some.url.1", success, failure );

In APIS of this desing, oftne the failure()error handler is optional, and if not provided it will be assumed you want thte erros swallowed. Ugh.

NOte: THis split-callback design is what hte ES6 promise API uses. WE'll coer ES6 promises in much more detail in the enext chapter.

Another common callback pattern is called "error-first style" sometimes called node style as its also the convention used accross nearly all node.js APIs where the first argument
of a single callback is reserved for an error object. If any. If succes, this argumetn will be empty/falsy and any subsequent arguments will be the success data but ifan error
result is being signaled, the first argument is set/truthy and nusually nothign else is passed.

function response(err,data) {
	// error?
	if (err) {
		console.error( err );
	}
	// otherwise, assume success
	else {
		console.log( data );
	}
}

ajax( "http://some.url.1", response );


IN both of htese cases, several things hsould be observed.
First, it has not really resolved the majority of trust issues like it may appear. There's ntohign about eitehr callbac that prevents or filters unwanted repeatd invocations. Morever, things are worse now,
because you may get both success and eror signals, or noeither, and you still have to code around either of those conditions.

Also don't miss the fact that while its a standard pattern you can employ, its definitely more verbose and boilerplate-ish without much reuse, so you're going to get weary of typing all that out for everyf single callback in your application.
What about hte trust issue of never being calle? If  this is a concern (and it probably should be!) yo ulike will need to set up a timeout that cancels the event. you could make
a utility 

function timeoutify(fn,delay) {
	var intv = setTimeout( function(){
			intv = null;
			fn( new Error( "Timeout!" ) );
		}, delay )
	;

	return function() {
		// timeout hasn't happened yet?
		if (intv) {
			clearTimeout( intv );
			fn.apply( this, [ null ].concat( [].slice.call( arguments ) ) );
		}
	};
}

Anotehr trust issue is being called "too early" In application specific terms, this may actually involve being called
before some critical task is complete. But more generally, the problem is evident in utilities that can either invoke the callback you provide now (synchronously) or later (asynchronously)

This nondeterminism around the async-or-async behavior is almost always going to lead to very difficult to track down bugs. In some circles, the fictional insanity-inducin monster
named Zalgo is used to describe the sync-async nightmores. "don't release Zalgo!" is a common cry, and it leads to very sound advice.
Always invoke callbacks asynchronously, even if that's "right away" on the next turn of the ven tloop, so that all callbacks are predictably async.

The asynchronous request in the cache "solves" the issue, but its inefficient, and yet again more bloated boilerplate to weight your project down.
Thats just hte sotry, ove rande over again, with callbacks. They can do prety much anything youw ant. But you ahve to be willign to work hard to ge tit,
and oftentimes this effort is much more than you can or should spend on such code reasoning.

You might find yourself wishig for built-in API's or other language mechanics toa ddress these isuses.
Finnaly ES6 ha arrived ont he scen with some great answers, so keep reading!

Review:
Callbacks are the fundamental unit of asynchrony in JS. but they're not enough for the evolving landscape of async programming as JS matures.

FIrst, our brains plan things out in sequential, blocking, single-threaded semantic ways bt callbacks express asynchronous flow in a rather nonlinear, nonsequential way, whihc makes reassoning properly 
about such code much harder. Bad to reason about code is bad tcod etha tleads to bad bugs. 

We need a way to express asynchrony in a more synchronus, sequntial, blocking manner, just like our brains do.
We need a way to express asynchrony in a more synchronous, sequential, blocking manner, just like our brains do.

Second, and more importantly, callbacks suffer from inversion of control in that they implicitly give control over to another party (often a third-party utility not in your control!) to invoke the continuation of your program. This control transfer leads us to a troubling list of trust issues, such as whether the callback is called more times than we expect.

Inventing ad hoc logic to solve these trust issues is possible, but it's more difficult than it should be, and it produces clunkier and harder to maintain code, as well as code that is likely insufficiently protected from these hazards until you get visibly bitten by the bugs.

We need a generalized solution to all of the trust issues, one that can be reused for as many callbacks as we create without all the extra boilerplate overhead.

We need something better than callbacks. They've served us well to this point, but the future of JavaScript demands more sophisticated and capable async patterns. The subsequent chapters in this book will dive into those emerging evolutions.




u-Dont-Know-JS/blob/1st-ed/async%20%26%20performance/ch3.md
You don't know JS: ASYNC AND PERFORMANCE
Chapter 3: Promises.

In chapter 2, we identified two major categories of deficiencies with using callbacks to express program asynchrony and manage concurrency.
Lack of sequentiality and lack of trustability. Now that we understand the problems more intimately, its time we turn our attention to patterns that can address them.

The issue we want to address first is the inversion of controlk, the trust that is so frageily held and so easily lost.

Recall that we wrap up the contiuation of our program in a  callback function, and hand that callback over to another party
(potentially even external code) and just cross our fingers that it willl do the right thing with the invocatin of the callback.
We do this because we want to say that "here what happens LATER, after the currne step finishes"
But hwat if we could uninvert the inversion of cohntrol? What if instead of handing the continuation of our program to another party, we could expect it to return us a capability
to know when its task finishes, and then our code could decide what to do next?


This paradigm is called PROMISES.
Promises are starting to take the javascript world by storm ,as deveopers and specification writers alike desperately seek to untangle the insanity of callback hell in their code/desin. In fact,
most new async APIs are being added to JS/DOM platform are being built on promises. So its probably a good idea to dig in and learn hteml, don't you thinK?


What is a promise?:
When developers decide to learn a new tehcnology or pattern, usually their first step is "show me the code!" its quite natural for us ot just jump in and learn as we go.
But it turn sout that some abstractions get lost on the APIS alone. Promises are one of htose tools where it can be painfully obvious from how someone uses it whether they udnerstand what its for and about
vereuss just learning  and using the API.

Future Value:
IMagine this scenario: I walk up to the counter at a fast-food restaurant and place an  orer for a cheeseburger. I hand the cvashier 1.47. By placing my order and paying for it, I've made a request for a value back (the cheeseburger)
I've started a transaction.
But often, the cheesebruger is not immediately available for me. The cashier hands me something in place of my cheeseburger: a receipt with an order number on it. THi soder numebr is an IOU PROMISE that ensures
that eventually, I shoudl receive a cheesebruger.

So I hold onto my receipt and order number. I know it rerpesents my future cheeseburger, so I don't need to wayy about ti anymore -- aside from being hungry!

While I wait, I can do other things, like send a text message to af riend saying "hey can you come join me for lunch? I'm going to eat a cheeseburger."

I am reasoning about my FUTURE fcheeseburger already, even though I don't have it ihn my haneds yet. My brain
is able to do this beecause its treating the order number as a placeholder for the cheeseurger. The placeholder essentially amkes the value time independent. Its a future value.


Eventulaly I hear "Order 113!" and I gleefully walk back up to th ecounter wiht receipt in hand. I hand my receip tto ehc cashier, and I take my cheeseburger in return.
In other words, once my future value was ready, I exchanged my value-promise for the value itself.

But there's another possible outcome. They call my order number, but when I go to retrieve my cheeseburger, the cashier
regretfully informs me, I'm sorry, but we we appear to be all out of cheeseburgerS" Setting aside the customer frustration of htis scenario for a moement, we can see
an important characteristic of future values: They ca n either indicate a success or failure.

Every time I order a cheeseburer, I know that i'll eitehr get a cheeseburger eventually, or i'll get the sad news of th cheesebrger shortage, and I"ll have to figure out something else to eat for lunch.
Note: In ocde, things are not quite as simple, because metaphorically the order number may never be called, in which case we're left indefinitely in an unresolved state.


Values now and later:
This all might soudn too mentally abstract to apply to your code, so lets be more concrete. 
However, before we canintroduce how promises work in this fashion, we're going to derivce in code that we already udnerstand. Callbacks! How to handle these future values.
When you write code too reason about a value, such as perfomring math on a number, whether you realize it or not, you've been assuming something very fundamentalabout that value, which is that its s a contcrete now value.


var x, y = 2;

console.log( x + y ); // NaN  <-- because `x` isn't set yet

The x + y operation assumes both x and y are alrady set. In terms we'll expounnd on shortly, we assume the x and y values are already resolved.

It would be nonsense to expeft the + operator by itself would somehow be magicvally capable
of detecting and waiting around until both x and y are resolved, only then to do the operation.
That owuld cause chaos in the program if different statements finished NOW and others finishhed later right?


How oculd you possibly reason about the relationships between two statements if either one (or both) of them might not be finished yet?
If statement 2 relies on statement1 being finished, there are just two outcomes: eitehr statement1 finished right NOW and everything proceeeds fine,
or statement1 didn't finish yet, and thus staement 2 is going to fail.

function add(getX,getY,cb) {
	var x, y;
	getX( function(xVal){
		x = xVal;
		// both are ready?
		if (y != undefined) {
			cb( x + y );	// send along sum
		}
	} );
	getY( function(yVal){
		y = yVal;
		// both are ready?
		if (x != undefined) {
			cb( x + y );	// send along sum
		}
	} );
}

// `fetchX()` and `fetchY()` are sync or async
// functions
add( fetchX, fetchY, function(sum){
	console.log( sum ); // that was easy, huh?
} );


When the ugliness is undeniable, theres something very important to notice about this async pattern.
in that snippet, we treated x and y as future values,a nd we express an operation add(...) that from the outside
does not care whether x or y or both are available right away or not. In other words, it noramlizes the now and later,
such taht we can rely on a predictable outcome of the add(...) operation

By using an add.... that is temporally consistent -- it behaves the same acrross now and later itmes 
the async code is much easier to reason about.

To put it more plainly: to consistently handle both now and later, we both make both of them later: all operations become async,

Of course, th is rough callbacks based approach laeaves much to be desired. its just a first tiny step twoards realizing theb enfits
of reasoning baout future values wihtout worrying about the time aspect of hwne its available or not.

Promise value:
We'll definitely go into more detail about promises later in the chapter.
function add(xPromise,yPromise) {
	// `Promise.all([ .. ])` takes an array of promises,
	// and returns a new promise that waits on them
	// all to finish
	return Promise.all( [xPromise, yPromise] )

	// when that promise is resolved, let's take the
	// received `X` and `Y` values and add them together.
	.then( function(values){
		// `values` is an array of the messages from the
		// previously resolved promises
		return values[0] + values[1];
	} );
}

// `fetchX()` and `fetchY()` return promises for
// their respective values, which may be ready
// *now* or *later*.
add( fetchX(), fetchY() )

// we get a promise back for the sum of those
// two numbers.
// now we chain-call `then(..)` to wait for the
// resolution of that returned promise.
.then( function(sum){
	console.log( sum ); // that was easier!
} );


There are two layers of promises in this snippet.
fetchX() and fetvchY() are called irectly, and the values they return (promises) are passed into add(....)
the underlyuing values those promises represent may be ready now or later, but each promise noramlizes the bhavior to be the same regardless. We reason about X and Y values in a timer independent way.
They are future values.

The second layer is the promise that addd(...) creates (vvia Promise.all) and returns, which we wait on by calling then(...) when the add(...)
operation completes, our sum future value is ready and we can print it out. WE hid inside of add(..) the logic for waiting ont he x and y future values.


Note: Inside add(..), the Promise.all([ .. ]) call creates a promise (which is waiting on promiseX and promiseY to resolve). The chained call to .then(..) creates another promise, which
 the return values[0] + values[1] line immediately resolves (with the result of the addition). Thus, the then(..) call we chain off the end of the add(..) call -- at the end of the snippet
  -- is actually operating on that second promise returned, rather than the first one created by Promise.all([ .. ]). Also, though we are not chaining off the end of that second then(..), it too has created another promise, had we chosen to observe/use it. This Promise chaining stuff will be explained in much greater detail later in this chapter.



Just like with cheeseburger orders, it's possible that the resolution of a Promise is rejection instead of fulfillment. Unlike a fulfilled Promise, where the value is always programmatic, a rejection value -- commonly called a "rejection reason" -- can either be set directly by the program logic, or it can result implicitly from a runtime exception.

With Promises, the then(..) call can actually take two functions, the first for fulfillment (as shown earlier), and the second for rejection:

add( fetchX(), fetchY() )
.then(
	// fulfillment handler
	function(sum) {
		console.log( sum );
	},
	// rejection handler
	function(err) {
		console.error( err ); // bummer!
	}
);


If something went wrong with getting x or y, or something somehow failed during the addition, the promise that add(...) returns is rejected, and the second callback error handler
passed to the then(...) will receive the rejection value from the promise.

Because promises encapsluate the time-dependent state -- waiting on the fulfillment or rejection of the underlying value -- from the outside, the promise itself is time-independent, and thus promises can becomposed (combined in predictable ways regardless of the timing or outcome underneat.)

Moreover, once a promise is resolved, it stays that way forever -- itbecomes an immutable value ant that point -- and can be observed as many times as necessary.

add( fetchX(), fetchY() )
.then(
	// fulfillment handler
	function(sum) {
		console.log( sum );
	},
	// rejection handler
	function(err) {
		console.error( err ); // bummer!
	}
);
If something went wrong getting X or Y, or something somehow failed during the addition, the promise that add(..) returns is rejected, and the second callback error handler passed to then(..) will receive the rejection value from the promise.

Because Promises encapsulate the time-dependent state -- waiting on the fulfillment or rejection of the underlying value -- from the outside, the Promise itself is time-independent, and thus Promises can be composed (combined) in predictable ways regardless of the timing or outcome underneath.

Moreover, once a Promise is resolved, it stays that way forever -- it becomes an immutable value at that point -- and can then be observed as many times as necessary.

Note: Because a Promise is externally immutable once resolved, it's now safe to pass that value around to any party and know that it cannot be modified accidentally or maliciously. This is especially true in relation to multiple parties observing the resolution of a Promise. It is not possible for one party to affect another party's ability to observe Promise resolution. Immutability may sound like an academic topic, but it's actually one of the most fundamental and important aspects of Promise design, and shouldn't be casually passed over.

That's one of the most powerful and important concepts to understand about Promises. With a fair amount of work, you could ad hoc create the same effects with nothing but ugly callback composition, but that's not really an effective strategy, especially because you have to do it over and over again.

Promises are an easily repeatable mechanism for encapsulating and composing future values.



Completion Event:
As we just saw, an individual promise behaves as a future value. But there's anohte rway to think of the resolution as a promise: as a flow-control mechanism -- a temporal this th en that for two or more steps in an asynchronous task.
Lets imagine the calling a function foo(...) to perform some tak. We don't nkow about any of its details, nor do we care. It may complete the task right awya, or it may take awhile.
We just simply need to know when foo() finishes so that we3 can move on to our next task. In other words, we'd like a away to be notified of foo()'s completeion so that we can continue.

In typical javascript fashion, you need to listen for a notifcation, you'd likely think of that in terms of events.
So we could reframe our need for notification as a need to listen for a completion.

Note: Whether you call it a "completion event" or a "continuation event" depends on your perspective. Is the focus more on what happens with foo(..), or what happens after foo(..) finishes? Both perspectives are accurate and useful.
 The event notification tells us that foo(..) has completed, but also that it's OK to continue with the next step. Indeed, the callback you pass to be called for the event notification is itself what we've previously called a continuation. 
 Because completion event is a bit more focused on the foo(..), which more has our attention at present, we slightly favor completion event for the rest of this text.

foo(x) {
	// start doing something that could take a while
}

foo( 42 )

on (foo "completion") {
	// now we can do the next step!
}

on (foo "error") {
	// oops, something went wrong in `foo(..)`
}



WE call foo(...) and then we set up two event listeners, one for "completion" and one for "error"
-the two poossible final outocmes of the foo(*...) call. In essence, foo(...) doesn't even appear to be aware that the calling code
has subscribed to these events, which makes for a very nice seeparatino of concerns.

Unfortunately, such code would require some "magic" of the JS environment that doens't exist
and would likely be a bitimpractical
function foo(x) {
	// start doing something that could take a while

	// make a `listener` event notification
	// capability to return

	return listener;
}

var evt = foo( 42 );

evt.on( "completion", function(){
	// now we can do the next step!
} );

evt.on( "failure", function(err){
	// oops, something went wrong in `foo(..)`
} );

foo(..) expressly creates an event subscription capability to return back, and the calling code receives and registers the two event handlers against it.

The inversion from normal callback-oriented code should be obvious, and it's intentional. Instead of passing the callbacks to foo(..), it returns an event capability we call evt, which receives the callbacks.

But if you recall from Chapter 2, callbacks themselves represent an inversion of control. So inverting the callback pattern is actually an inversion of inversion, or an uninversion of control -- restoring control back to the calling code where we wanted it to be in the first place.

One important benefit is that multiple separate parts of the code can be given the event listening capability, and they can all independently be notified of when foo(..) completes to perform subsequent steps after its completion:


var evt = foo( 42 );

// let `bar(..)` listen to `foo(..)`'s completion
bar( evt );

// also, let `baz(..)` listen to `foo(..)`'s completion
baz( evt );